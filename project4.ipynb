{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Web Scraping Job Postings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Case Overview\n",
    "\n",
    "You're working as a data scientist for a contracting firm that's rapidly expanding. Now that they have their most valuable employee (you!), they need to leverage data to win more contracts. Your firm offers technology and scientific solutions and wants to be competitive in the hiring market. Your principal has two main objectives:\n",
    "\n",
    "   1. Determine the industry factors that are most important in predicting the salary amounts for these data.\n",
    "   2. Determine the factors that distinguish job categories and titles from each other. For example, can required skills accurately predict job title?\n",
    "\n",
    "To limit the scope, your principal has suggested that you *focus on data-related job postings*, e.g. data scientist, data analyst, research scientist, business intelligence, and any others you might think of. You may also want to decrease the scope by *limiting your search to a single region.*\n",
    "\n",
    "Hint: Aggregators like [Indeed.com](https://www.indeed.com) regularly pool job postings from a variety of markets and industries. \n",
    "\n",
    "**Goal:** Scrape your own data from a job aggregation tool like Indeed.com in order to collect the data to best answer these two questions.\n",
    "\n",
    "---\n",
    "\n",
    "## Directions\n",
    "\n",
    "In this project you will be leveraging a variety of skills. The first will be to use the web-scraping and/or API techniques you've learned to collect data on data jobs from Indeed.com or another aggregator. Once you have collected and cleaned the data, you will use it to answer the two questions described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping the Data from Indeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load required scripts\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import urllib, requests, re, pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List various salary bandings for data scientist jobs in California\n",
    "# Salary banding according to the suggested estimates by Indeed\n",
    "base_url_ca_60 = 'https://www.indeed.com/jobs?q=Data+Scientist+$60,000&l=California&radius=50&jt=fulltime&sort='\n",
    "base_url_ca_80 = 'https://www.indeed.com/jobs?q=Data+Scientist+$80,000&l=California&radius=50&jt=fulltime&sort='\n",
    "base_url_ca_95 = 'https://www.indeed.com/jobs?q=Data+Scientist+$95,000&l=California&radius=50&jt=fulltime&sort='\n",
    "base_url_ca_110 = 'https://www.indeed.com/jobs?q=Data+Scientist+$110,000&l=California&radius=50&jt=fulltime&sort='\n",
    "\n",
    "# Sort data by date and by start page number (to append later)\n",
    "sort_by = 'date'          \n",
    "start_from = '&start='    \n",
    "\n",
    "# Remove the column limit for pandas\n",
    "pd.set_option('max_colwidth',500)   \n",
    "\n",
    "# Pre-establish the database\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(df, base_url, salary_estimate) :\n",
    "    \"\"\" Takes in a dataframe and then scrapes Indeed.com for jobs using the base URL\n",
    "    provided by the user. For user's own reference, include the salary estimate parameter\n",
    "    used for the job search. \"\"\"\n",
    "\n",
    "    # Scrape page 1 to 100 (last accessible page is 100)\n",
    "    for page in range(1,101):\n",
    "        \n",
    "        # Multiple by 10 as the numbers follow number of jobs listed per page\n",
    "        page = (page-1) * 10  \n",
    "        \n",
    "        # Create full URL\n",
    "        url = \"%s%s%s%d\" % (base_url, sort_by, start_from, page)\n",
    "        \n",
    "        # Scrape\n",
    "        target = Soup(urllib.urlopen(url), \"lxml\") \n",
    "\n",
    "        # Get a job from each row\n",
    "        targetElements = target.findAll('div', attrs={'class':\" row result\"})\n",
    "    \n",
    "        # Try to get each specific job information\n",
    "        for elem in targetElements: \n",
    "            try:\n",
    "                comp_name = elem.find('span', attrs={'class':'company'}).getText().strip()\n",
    "            except: \n",
    "                comp_name = None\n",
    "                \n",
    "            try:\n",
    "                job_title = elem.find('a', attrs={'class':'turnstileLink'}).attrs['title']\n",
    "            except:\n",
    "                job_title = None\n",
    "            \n",
    "            try:\n",
    "                listed_job_salary = elem.find('span', attrs={'class': \"no-wrap\"}).getText()\n",
    "            except:\n",
    "                listed_job_salary = None\n",
    "            \n",
    "            try:\n",
    "                job_addr = elem.find('span', attrs={'class':'location'}).getText()\n",
    "            except:\n",
    "                job_addr = None\n",
    "            \n",
    "            try:\n",
    "                job_summary = elem.find('span', attrs={'class': 'summary'}).getText()\n",
    "            except:\n",
    "                job_summary = None\n",
    "\n",
    "\n",
    "            # Add job info to the data frame\n",
    "            df = df.append({'comp_name': comp_name, 'job_title': job_title, \n",
    "                            'salary_estimated': salary_estimate,'job_summary' : job_summary,\n",
    "                            'job_location': job_addr, 'listed_job_salary' : listed_job_salary\n",
    "                           }, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape from the estimated $60,000 band\n",
    "df = scrape(df, base_url_ca_60, 60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape from the estimated $80,000 band\n",
    "df = scrape(df, base_url_ca_80, 80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape from the estimated $95,000 band\n",
    "df = scrape(df, base_url_ca_95, 95000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scrape from the estimated $110,000 band\n",
    "df = scrape(df, base_url_ca_110, 110000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the new line spacing from the dataframe\n",
    "df = df.replace('\\n','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result to CSV\n",
    "df.to_csv('../indeed-results.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in CSV so that we don't have to scrape again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_csv('../indeed-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$150,000 a year                                 17\n",
       "$140,000 - $165,000 a year                      13\n",
       "$120,000 - $150,000 a year                      12\n",
       "$150,000 - $180,000 a year                      11\n",
       "$180,000 a year                                 10\n",
       "$100,000 - $180,000 a year                       9\n",
       "$130,000 - $150,000 a year                       9\n",
       "$150,000 - $200,000 a year                       8\n",
       "$160,000 - $170,000 a year                       7\n",
       "$140,000 - $160,000 a year                       7\n",
       "$140,000 - $200,000 a year                       6\n",
       "$100,000 - $160,000 a year                       6\n",
       "$140,000 - $180,000 a year                       6\n",
       "$125,000 - $155,000 a year                       5\n",
       "$180,000 - $250,000 a year                       5\n",
       "$180,000 - $200,000 a year                       5\n",
       "$120,000 - $140,000 a year                       5\n",
       "$130,000 - $195,000 a year                       5\n",
       "$180,000 - $210,000 a year                       5\n",
       "$160,000 - $180,000 a year                       5\n",
       "$220,000 a year                                  5\n",
       "$300,000 a year                                  4\n",
       "$250,000 a year                                  4\n",
       "$100,000 - $155,000 a year                       4\n",
       "$190,000 a year                                  4\n",
       "$150,000 - $170,000 a year                       4\n",
       "$81,319 - $105,718 a year                        3\n",
       "$7,046 a month                                   3\n",
       "$145,000 - $200,000 a year                       3\n",
       "$140,000 - $170,000 a year                       3\n",
       "                                                ..\n",
       "$80,000 - $100,000 a year                        2\n",
       "$90,000 - $125,000 a year                        2\n",
       "$70,000 - $100,000 a year                        2\n",
       "$160,000 - $190,000 a year                       1\n",
       "$100,000 - $120,000 a year                       1\n",
       "$240,000 a year                                  1\n",
       "$3,897 - $6,453 a month                          1\n",
       "Estimated salary: $77,000 - $98,000 a year       1\n",
       "Estimated salary: $103,000 - $132,000 a year     1\n",
       "Estimated salary: $88,000 - $112,000 a year      1\n",
       "Estimated salary: $95,000 - $122,000 a year      1\n",
       "Estimated salary: $94,000 - $119,000 a year      1\n",
       "$78,546 - $95,498 a year                         1\n",
       "$55,000 - $65,000 a year                         1\n",
       "Estimated salary: $99,000 - $126,000 a year      1\n",
       "$160,000 a year                                  1\n",
       "$4,693 - $7,769 a month                          1\n",
       "$58,416 - $72,571 a year                         1\n",
       "Estimated salary: $88,000 - $111,000 a year      1\n",
       "$4,372 - $9,877 a month                          1\n",
       "Estimated salary: $104,000 - $132,000 a year     1\n",
       "$6,667 - $7,350 a month                          1\n",
       "Estimated salary: $113,000 - $144,000 a year     1\n",
       "Estimated salary: $109,000 - $139,000 a year     1\n",
       "$29.91 - $46.36 an hour                          1\n",
       "$85,795 - $104,285 a year                        1\n",
       "$5,988 - $6,322 a month                          1\n",
       "$100,000 - $130,000 a year                       1\n",
       "$90,000 - $120,000 a year                        1\n",
       "Estimated salary: $115,000 - $146,000 a year     1\n",
       "Name: listed_job_salary, Length: 92, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, we take a look at the number of listed salaries we have\n",
    "df_read[\"listed_job_salary\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:800px;background:#ffff00;border:1px solid black;text-align:left;padding:8px;\">\n",
    "\n",
    "Do some light cleaning here. Since we don't have a lot of jobs that have the listed salary (as expected), we will remove that column. We also suspect duplicates in jobs, so taking the job_summary column, we drop any duplicates found as it is unlikely that two different jobs will have identical, word-for-word descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_read.drop([\"Unnamed: 0\", \"listed_job_salary\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_estimated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart eCommerce</td>\n",
       "      <td>San Bruno, CA 94066</td>\n",
       "      <td>Data scientists, front and back-end engineers,...</td>\n",
       "      <td>Director, Retail Learning &amp; Development</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>Menlo Park, CA</td>\n",
       "      <td>Work with engineering, data science, and desig...</td>\n",
       "      <td>Product Manager, Advanced Network Planning</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kaiser Permanente</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>He or she will manage a team of analysts, data...</td>\n",
       "      <td>Senior Manager Decision Support</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PaxVax</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>Good data anaylsis skills. Is seeking a Scient...</td>\n",
       "      <td>Scientist, Process Development - Upstream</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Aerospace Corporation</td>\n",
       "      <td>El Segundo, CA 90245</td>\n",
       "      <td>Our state-of-the-art laboratory facilities are...</td>\n",
       "      <td>Associate Software Engineer</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   comp_name          job_location  \\\n",
       "0          Walmart eCommerce   San Bruno, CA 94066   \n",
       "1                   Facebook        Menlo Park, CA   \n",
       "2          Kaiser Permanente           Oakland, CA   \n",
       "3                     PaxVax         San Diego, CA   \n",
       "4  The Aerospace Corporation  El Segundo, CA 90245   \n",
       "\n",
       "                                         job_summary  \\\n",
       "0  Data scientists, front and back-end engineers,...   \n",
       "1  Work with engineering, data science, and desig...   \n",
       "2  He or she will manage a team of analysts, data...   \n",
       "3  Good data anaylsis skills. Is seeking a Scient...   \n",
       "4  Our state-of-the-art laboratory facilities are...   \n",
       "\n",
       "                                    job_title  salary_estimated  \n",
       "0     Director, Retail Learning & Development           60000.0  \n",
       "1  Product Manager, Advanced Network Planning           60000.0  \n",
       "2             Senior Manager Decision Support           60000.0  \n",
       "3   Scientist, Process Development - Upstream           60000.0  \n",
       "4                 Associate Software Engineer           60000.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_read.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:800px;background:#ffff00;border:1px solid black;text-align:left;padding:8px;\">\n",
    "\n",
    "Here we drop the duplicate job listings. We can determine this by checking for complete\n",
    "duplicates on the job descriptions because it is unlikely that two different jobs\n",
    "will have the exact same description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read.drop_duplicates(subset='job_summary', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1527, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_read.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000.0     725\n",
       "110000.0    294\n",
       "80000.0     286\n",
       "95000.0     222\n",
       "Name: salary_estimated, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_read.salary_estimated.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict salary you will be building either a classification or regression model, using features like the location, title, and summary of the job. If framing this as a regression problem, you will be estimating the listed salary amounts. You may instead choose to frame this as a classification problem, in which case you will create labels from these salaries (high vs. low salary, for example) according to thresholds (such as median salary).\n",
    "\n",
    "You have learned a variety of new skills and models that may be useful for this problem:\n",
    "- NLP\n",
    "- Unsupervised learning and dimensionality reduction techniques (PCA, clustering)\n",
    "- Ensemble methods and decision tree models\n",
    "- SVM models\n",
    "\n",
    "Whatever you decide to use, the most important thing is to justify your choices and interpret your results. *Communication of your process is key.* Note that most listings **DO NOT** come with salary information. You'll need to able to extrapolate or predict the expected salaries for these listings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## City Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:800px;background:#ffff00;border:1px solid black;text-align:left;padding:8px;\">\n",
    "\n",
    "First, we will utilize random forest classifiers to determine if a variable or combination of variables have a significant impact on whether a job's salary will be high or low. \n",
    "\n",
    "Here, we will start with the city variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60k and 80k will be considered low salary\n",
    "# 95k and 110k will be considered high salary\n",
    "\n",
    "df_read['high_salary'] = [1 if a > 80000 else 0 for a in df_read.salary_estimated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1011\n",
       "1     516\n",
       "Name: high_salary, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reasonably balanced distribution of high and low salary\n",
    "df_read.high_salary.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_estimated</th>\n",
       "      <th>high_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart eCommerce</td>\n",
       "      <td>San Brun</td>\n",
       "      <td>Data scientists, front and back-end engineers,...</td>\n",
       "      <td>Director, Retail Learning &amp; Development</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>Menlo Par</td>\n",
       "      <td>Work with engineering, data science, and desig...</td>\n",
       "      <td>Product Manager, Advanced Network Planning</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kaiser Permanente</td>\n",
       "      <td>Oaklan</td>\n",
       "      <td>He or she will manage a team of analysts, data...</td>\n",
       "      <td>Senior Manager Decision Support</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PaxVax</td>\n",
       "      <td>San Dieg</td>\n",
       "      <td>Good data anaylsis skills. Is seeking a Scient...</td>\n",
       "      <td>Scientist, Process Development - Upstream</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Aerospace Corporation</td>\n",
       "      <td>El Segund</td>\n",
       "      <td>Our state-of-the-art laboratory facilities are...</td>\n",
       "      <td>Associate Software Engineer</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Walmart eCommerce</td>\n",
       "      <td>San Brun</td>\n",
       "      <td>We constantly improve our products based on us...</td>\n",
       "      <td>Senior Android Engineer</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BeiGene</td>\n",
       "      <td>San Francisc</td>\n",
       "      <td>Collects and researches data; Review, query, a...</td>\n",
       "      <td>Director, Clinical Science</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ascent Services Group</td>\n",
       "      <td>South San Francisc</td>\n",
       "      <td>Interpret data and communicate results in depa...</td>\n",
       "      <td>Research Associate I</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Remind</td>\n",
       "      <td>San Francisc</td>\n",
       "      <td>Analyze data to identify trends and opportunit...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>First American</td>\n",
       "      <td>Agoura Hill</td>\n",
       "      <td>Knowledge and experience with diverse statisti...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rocket Lawyer</td>\n",
       "      <td>San Francisc</td>\n",
       "      <td>Define and implement KPIs, work with Data Engi...</td>\n",
       "      <td>Data Scientist, Marketing</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Uber</td>\n",
       "      <td>San Francisc</td>\n",
       "      <td>You are aware of the power of data. Big and de...</td>\n",
       "      <td>Machine Learning Systems Engineer - Routing</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Viatouch Media</td>\n",
       "      <td>San Dieg</td>\n",
       "      <td>ViaTouch currently working with world class cu...</td>\n",
       "      <td>AI/Machine Learning Developer</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Osaro</td>\n",
       "      <td>San Francisc</td>\n",
       "      <td>Experience interfacing with data sources and p...</td>\n",
       "      <td>Deep Learning Engineer</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Immucor, Inc</td>\n",
       "      <td>Mountain Vie</td>\n",
       "      <td>As our Bioinformatics Scientist, you will resp...</td>\n",
       "      <td>Bioinformatics Scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Siemens</td>\n",
       "      <td>Berkele</td>\n",
       "      <td>This Senior Scientist will. Sequencing data an...</td>\n",
       "      <td>Sr. Scientist, R&amp;D</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Brainworks</td>\n",
       "      <td>Oaklan</td>\n",
       "      <td>Our client, a fast-growing, well-funded, ecomm...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Qubol</td>\n",
       "      <td>Santa Clar</td>\n",
       "      <td>Host an office hours for analysts or data scie...</td>\n",
       "      <td>Duties</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Zymergen</td>\n",
       "      <td>Emeryvill</td>\n",
       "      <td>Operations and Data Analysis:. Familiarity wit...</td>\n",
       "      <td>Research Associate, CRISPR/Cas9 Genome Enginee...</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>California Institute of Technology</td>\n",
       "      <td>Pasaden</td>\n",
       "      <td>Develop and implement new technologies for rea...</td>\n",
       "      <td>Staff Seismologist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Staples</td>\n",
       "      <td>San Jos</td>\n",
       "      <td>Know how to access data and manipulate data fr...</td>\n",
       "      <td>Consultant Software Engineer</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ayasdi</td>\n",
       "      <td>Menlo Par</td>\n",
       "      <td>Gather &amp; prioritize input from sales, marketin...</td>\n",
       "      <td>Platform Product Manager (Machine Learning)</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Stanford University</td>\n",
       "      <td>Stanfor</td>\n",
       "      <td>Analyze data, monitor and oversee experimental...</td>\n",
       "      <td>Scanning Probe Microscopy Laboratory Manager</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Roche</td>\n",
       "      <td>Belmon</td>\n",
       "      <td>There's plenty of data being generated. You wi...</td>\n",
       "      <td>Sr. Software Engineer - Diagnostic Information...</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Roche</td>\n",
       "      <td>Belmon</td>\n",
       "      <td>We are rethinking the way that scientists, doc...</td>\n",
       "      <td>Sr. Product Manager</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Osaro</td>\n",
       "      <td>San Francisc</td>\n",
       "      <td>Experience interfacing with large data sources...</td>\n",
       "      <td>Software Engineer/DevOps</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Ardelyx</td>\n",
       "      <td>Fremon</td>\n",
       "      <td>Review and approve analytical/stability protoc...</td>\n",
       "      <td>Senior Director of Quality Assurance</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Celgene Corporation</td>\n",
       "      <td>San Dieg</td>\n",
       "      <td>Ability to analyze data and formulate solution...</td>\n",
       "      <td>Associate Operations Coordinator, Research All...</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Illumina</td>\n",
       "      <td>San Dieg</td>\n",
       "      <td>Presents data at scientific conferences. Exper...</td>\n",
       "      <td>Director, Product Development – Oncology</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Celgene Corporation</td>\n",
       "      <td>San Dieg</td>\n",
       "      <td>Analyze and present data. The team provides br...</td>\n",
       "      <td>Sr. Operations Coordinator, Research Alliance</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>Wish</td>\n",
       "      <td>San Francisc</td>\n",
       "      <td>Risk Data Scientist will be responsible for de...</td>\n",
       "      <td>Sr. Risk Data Scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>GoPro Careers Page</td>\n",
       "      <td>San Mate</td>\n",
       "      <td>Experience working with large data sets. To re...</td>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>LendUp</td>\n",
       "      <td>San Francisc</td>\n",
       "      <td>Learn from some of the smartest and most exper...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>Color Genomics</td>\n",
       "      <td>Burlingam</td>\n",
       "      <td>Working with Engineering to build infrastructu...</td>\n",
       "      <td>Head of Data Science</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>Grand Rounds</td>\n",
       "      <td>San Francisc</td>\n",
       "      <td>Previous experience working with data warehous...</td>\n",
       "      <td>Senior Product Manager - Data Services</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>Quora</td>\n",
       "      <td>Mountain Vie</td>\n",
       "      <td>Strong experience with complex interdependent ...</td>\n",
       "      <td>Site Reliability Engineer - Machine Learning S...</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>Boehringer Ingelheim</td>\n",
       "      <td>Fremon</td>\n",
       "      <td>Provides comprehensive training and guidance t...</td>\n",
       "      <td>Senior Engineer/Principal Engineer, Manufactur...</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>Jazz Pharmaceuticals</td>\n",
       "      <td>Palo Alt</td>\n",
       "      <td>This person will provide leadership and lead a...</td>\n",
       "      <td>Executive Director, Clinical Development Sleep...</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>Netflix</td>\n",
       "      <td>Los Gato</td>\n",
       "      <td>As a senior data scientist, you will answer, t...</td>\n",
       "      <td>Senior Data Scientist, Original Content Promotion</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>Proofpoint</td>\n",
       "      <td>Sunnyval</td>\n",
       "      <td>Must have been in the role of data scientist f...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>View, Inc.</td>\n",
       "      <td>Milpita</td>\n",
       "      <td>Experience building highly scalable solutions ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>KLA-Tencor</td>\n",
       "      <td>Milpita</td>\n",
       "      <td>Responsibility will include the development of...</td>\n",
       "      <td>Machine Learning Data Visualization</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>Blue River Technology</td>\n",
       "      <td>Sunnyval</td>\n",
       "      <td>Helping to architect and develop data processi...</td>\n",
       "      <td>Research Scientist - Deep Learning</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>Twitch</td>\n",
       "      <td>San Francisc</td>\n",
       "      <td>This team is comprised of business leaders, en...</td>\n",
       "      <td>Manager of Strategy and Operations - Commerce</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>LogMeIn, Inc.</td>\n",
       "      <td>Mountain Vie</td>\n",
       "      <td>Work with Data Scientists to continuously anal...</td>\n",
       "      <td>Lead Software Engineer, Machine Learning</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>Pfizer</td>\n",
       "      <td>San Francisc</td>\n",
       "      <td>Accountabilities include the design, developme...</td>\n",
       "      <td>Data Monitoring and Management Group Lead (Dir...</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>[24]7</td>\n",
       "      <td>Californ</td>\n",
       "      <td>You will be working closely with data scientis...</td>\n",
       "      <td>Principal Software Engineer, OmniChannel Platf...</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>10x Genomics</td>\n",
       "      <td>Pleasanto</td>\n",
       "      <td>Train and mentor junior scientist in the depar...</td>\n",
       "      <td>Principal Scientist - Molecular Biology</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>Southern California Edison</td>\n",
       "      <td>Rosemea</td>\n",
       "      <td>In-depth understanding of data analytics, data...</td>\n",
       "      <td>Senior Project Manager Data Analytics Systems</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>Bossanova Robotics</td>\n",
       "      <td>San Francisc</td>\n",
       "      <td>MS or PhD in computer science, electrical engi...</td>\n",
       "      <td>AI Lead Engineer</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>Modest</td>\n",
       "      <td>Digital Data Scientist PM. Statistics, marketi...</td>\n",
       "      <td>Digital Data Scientist, PM</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>SAIC</td>\n",
       "      <td>Montere</td>\n",
       "      <td>This includes monitoring of both the data avai...</td>\n",
       "      <td>NRL NWP Model Evaluator/Statistician Job</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>Walmart eCommerce</td>\n",
       "      <td>San Brun</td>\n",
       "      <td>Experienced working with massive, messy data s...</td>\n",
       "      <td>Statistician</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>Chan Zuckerberg Biohub</td>\n",
       "      <td>San Francisc</td>\n",
       "      <td>Developing algorithms for retrieval of physica...</td>\n",
       "      <td>Scientist/Engineer - Computational Microscopy</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>Udacity, Inc.</td>\n",
       "      <td>San Francisc</td>\n",
       "      <td>Lead and grow a team of data scientists and an...</td>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>Symantec</td>\n",
       "      <td>Mountain Vie</td>\n",
       "      <td>Cyber insurance is a financial product that is...</td>\n",
       "      <td>Data Scientist, Underwriting Customer Enablement</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>TrueAccord</td>\n",
       "      <td>San Francisc</td>\n",
       "      <td>60%, hands on data scientist:. Core Data Scien...</td>\n",
       "      <td>Director of Data Science</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>Life360</td>\n",
       "      <td>San Francisc</td>\n",
       "      <td>Lead Data Scientist -- Applied Machine Learnin...</td>\n",
       "      <td>Lead Data Scientist - Applied Machine Learning</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>SAIC</td>\n",
       "      <td>Montere</td>\n",
       "      <td>Data assimilation, including observational dat...</td>\n",
       "      <td>NRL Research Meteorologist Job</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>HomeLight</td>\n",
       "      <td>San Francisc</td>\n",
       "      <td>Professional experience in developing a data p...</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1527 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               comp_name        job_location  \\\n",
       "0                      Walmart eCommerce            San Brun   \n",
       "1                               Facebook           Menlo Par   \n",
       "2                      Kaiser Permanente              Oaklan   \n",
       "3                                 PaxVax            San Dieg   \n",
       "4              The Aerospace Corporation           El Segund   \n",
       "5                      Walmart eCommerce            San Brun   \n",
       "6                                BeiGene        San Francisc   \n",
       "7                  Ascent Services Group  South San Francisc   \n",
       "8                                 Remind        San Francisc   \n",
       "9                         First American         Agoura Hill   \n",
       "10                         Rocket Lawyer        San Francisc   \n",
       "11                                  Uber        San Francisc   \n",
       "12                        Viatouch Media            San Dieg   \n",
       "13                                 Osaro        San Francisc   \n",
       "14                          Immucor, Inc        Mountain Vie   \n",
       "15                               Siemens             Berkele   \n",
       "16                            Brainworks              Oaklan   \n",
       "17                                 Qubol          Santa Clar   \n",
       "18                              Zymergen           Emeryvill   \n",
       "19    California Institute of Technology             Pasaden   \n",
       "20                               Staples             San Jos   \n",
       "21                                Ayasdi           Menlo Par   \n",
       "22                   Stanford University             Stanfor   \n",
       "23                                 Roche              Belmon   \n",
       "24                                 Roche              Belmon   \n",
       "25                                 Osaro        San Francisc   \n",
       "26                               Ardelyx              Fremon   \n",
       "27                   Celgene Corporation            San Dieg   \n",
       "28                              Illumina            San Dieg   \n",
       "29                   Celgene Corporation            San Dieg   \n",
       "...                                  ...                 ...   \n",
       "1497                                Wish        San Francisc   \n",
       "1498                  GoPro Careers Page            San Mate   \n",
       "1499                              LendUp        San Francisc   \n",
       "1500                      Color Genomics           Burlingam   \n",
       "1501                        Grand Rounds        San Francisc   \n",
       "1502                               Quora        Mountain Vie   \n",
       "1503                Boehringer Ingelheim              Fremon   \n",
       "1504                Jazz Pharmaceuticals            Palo Alt   \n",
       "1505                             Netflix            Los Gato   \n",
       "1506                          Proofpoint            Sunnyval   \n",
       "1507                          View, Inc.             Milpita   \n",
       "1508                          KLA-Tencor             Milpita   \n",
       "1509               Blue River Technology            Sunnyval   \n",
       "1510                              Twitch        San Francisc   \n",
       "1511                       LogMeIn, Inc.        Mountain Vie   \n",
       "1512                              Pfizer        San Francisc   \n",
       "1513                               [24]7            Californ   \n",
       "1514                        10x Genomics           Pleasanto   \n",
       "1515          Southern California Edison             Rosemea   \n",
       "1516                  Bossanova Robotics        San Francisc   \n",
       "1517                    All-In Analytics              Modest   \n",
       "1518                                SAIC             Montere   \n",
       "1519                   Walmart eCommerce            San Brun   \n",
       "1520              Chan Zuckerberg Biohub        San Francisc   \n",
       "1521                       Udacity, Inc.        San Francisc   \n",
       "1522                            Symantec        Mountain Vie   \n",
       "1523                          TrueAccord        San Francisc   \n",
       "1524                             Life360        San Francisc   \n",
       "1525                                SAIC             Montere   \n",
       "1526                           HomeLight        San Francisc   \n",
       "\n",
       "                                            job_summary  \\\n",
       "0     Data scientists, front and back-end engineers,...   \n",
       "1     Work with engineering, data science, and desig...   \n",
       "2     He or she will manage a team of analysts, data...   \n",
       "3     Good data anaylsis skills. Is seeking a Scient...   \n",
       "4     Our state-of-the-art laboratory facilities are...   \n",
       "5     We constantly improve our products based on us...   \n",
       "6     Collects and researches data; Review, query, a...   \n",
       "7     Interpret data and communicate results in depa...   \n",
       "8     Analyze data to identify trends and opportunit...   \n",
       "9     Knowledge and experience with diverse statisti...   \n",
       "10    Define and implement KPIs, work with Data Engi...   \n",
       "11    You are aware of the power of data. Big and de...   \n",
       "12    ViaTouch currently working with world class cu...   \n",
       "13    Experience interfacing with data sources and p...   \n",
       "14    As our Bioinformatics Scientist, you will resp...   \n",
       "15    This Senior Scientist will. Sequencing data an...   \n",
       "16    Our client, a fast-growing, well-funded, ecomm...   \n",
       "17    Host an office hours for analysts or data scie...   \n",
       "18    Operations and Data Analysis:. Familiarity wit...   \n",
       "19    Develop and implement new technologies for rea...   \n",
       "20    Know how to access data and manipulate data fr...   \n",
       "21    Gather & prioritize input from sales, marketin...   \n",
       "22    Analyze data, monitor and oversee experimental...   \n",
       "23    There's plenty of data being generated. You wi...   \n",
       "24    We are rethinking the way that scientists, doc...   \n",
       "25    Experience interfacing with large data sources...   \n",
       "26    Review and approve analytical/stability protoc...   \n",
       "27    Ability to analyze data and formulate solution...   \n",
       "28    Presents data at scientific conferences. Exper...   \n",
       "29    Analyze and present data. The team provides br...   \n",
       "...                                                 ...   \n",
       "1497  Risk Data Scientist will be responsible for de...   \n",
       "1498  Experience working with large data sets. To re...   \n",
       "1499  Learn from some of the smartest and most exper...   \n",
       "1500  Working with Engineering to build infrastructu...   \n",
       "1501  Previous experience working with data warehous...   \n",
       "1502  Strong experience with complex interdependent ...   \n",
       "1503  Provides comprehensive training and guidance t...   \n",
       "1504  This person will provide leadership and lead a...   \n",
       "1505  As a senior data scientist, you will answer, t...   \n",
       "1506  Must have been in the role of data scientist f...   \n",
       "1507  Experience building highly scalable solutions ...   \n",
       "1508  Responsibility will include the development of...   \n",
       "1509  Helping to architect and develop data processi...   \n",
       "1510  This team is comprised of business leaders, en...   \n",
       "1511  Work with Data Scientists to continuously anal...   \n",
       "1512  Accountabilities include the design, developme...   \n",
       "1513  You will be working closely with data scientis...   \n",
       "1514  Train and mentor junior scientist in the depar...   \n",
       "1515  In-depth understanding of data analytics, data...   \n",
       "1516  MS or PhD in computer science, electrical engi...   \n",
       "1517  Digital Data Scientist PM. Statistics, marketi...   \n",
       "1518  This includes monitoring of both the data avai...   \n",
       "1519  Experienced working with massive, messy data s...   \n",
       "1520  Developing algorithms for retrieval of physica...   \n",
       "1521  Lead and grow a team of data scientists and an...   \n",
       "1522  Cyber insurance is a financial product that is...   \n",
       "1523  60%, hands on data scientist:. Core Data Scien...   \n",
       "1524  Lead Data Scientist -- Applied Machine Learnin...   \n",
       "1525  Data assimilation, including observational dat...   \n",
       "1526  Professional experience in developing a data p...   \n",
       "\n",
       "                                              job_title  salary_estimated  \\\n",
       "0               Director, Retail Learning & Development           60000.0   \n",
       "1            Product Manager, Advanced Network Planning           60000.0   \n",
       "2                       Senior Manager Decision Support           60000.0   \n",
       "3             Scientist, Process Development - Upstream           60000.0   \n",
       "4                           Associate Software Engineer           60000.0   \n",
       "5                               Senior Android Engineer           60000.0   \n",
       "6                            Director, Clinical Science           60000.0   \n",
       "7                                  Research Associate I           60000.0   \n",
       "8                                        Data Scientist           60000.0   \n",
       "9                                        Data Scientist           60000.0   \n",
       "10                            Data Scientist, Marketing           60000.0   \n",
       "11          Machine Learning Systems Engineer - Routing           60000.0   \n",
       "12                        AI/Machine Learning Developer           60000.0   \n",
       "13                               Deep Learning Engineer           60000.0   \n",
       "14                             Bioinformatics Scientist           60000.0   \n",
       "15                                   Sr. Scientist, R&D           60000.0   \n",
       "16                                       Data Scientist           60000.0   \n",
       "17                                               Duties           60000.0   \n",
       "18    Research Associate, CRISPR/Cas9 Genome Enginee...           60000.0   \n",
       "19                                   Staff Seismologist           60000.0   \n",
       "20                         Consultant Software Engineer           60000.0   \n",
       "21          Platform Product Manager (Machine Learning)           60000.0   \n",
       "22         Scanning Probe Microscopy Laboratory Manager           60000.0   \n",
       "23    Sr. Software Engineer - Diagnostic Information...           60000.0   \n",
       "24                                  Sr. Product Manager           60000.0   \n",
       "25                             Software Engineer/DevOps           60000.0   \n",
       "26                 Senior Director of Quality Assurance           60000.0   \n",
       "27    Associate Operations Coordinator, Research All...           60000.0   \n",
       "28             Director, Product Development – Oncology           60000.0   \n",
       "29        Sr. Operations Coordinator, Research Alliance           60000.0   \n",
       "...                                                 ...               ...   \n",
       "1497                            Sr. Risk Data Scientist          110000.0   \n",
       "1498                                 Sr. Data Scientist          110000.0   \n",
       "1499                              Senior Data Scientist          110000.0   \n",
       "1500                               Head of Data Science          110000.0   \n",
       "1501             Senior Product Manager - Data Services          110000.0   \n",
       "1502  Site Reliability Engineer - Machine Learning S...          110000.0   \n",
       "1503  Senior Engineer/Principal Engineer, Manufactur...          110000.0   \n",
       "1504  Executive Director, Clinical Development Sleep...          110000.0   \n",
       "1505  Senior Data Scientist, Original Content Promotion          110000.0   \n",
       "1506                                     Data Scientist          110000.0   \n",
       "1507                                     Data Scientist          110000.0   \n",
       "1508                Machine Learning Data Visualization          110000.0   \n",
       "1509                 Research Scientist - Deep Learning          110000.0   \n",
       "1510      Manager of Strategy and Operations - Commerce          110000.0   \n",
       "1511           Lead Software Engineer, Machine Learning          110000.0   \n",
       "1512  Data Monitoring and Management Group Lead (Dir...          110000.0   \n",
       "1513  Principal Software Engineer, OmniChannel Platf...          110000.0   \n",
       "1514            Principal Scientist - Molecular Biology          110000.0   \n",
       "1515      Senior Project Manager Data Analytics Systems          110000.0   \n",
       "1516                                   AI Lead Engineer          110000.0   \n",
       "1517                         Digital Data Scientist, PM          110000.0   \n",
       "1518           NRL NWP Model Evaluator/Statistician Job          110000.0   \n",
       "1519                                       Statistician          110000.0   \n",
       "1520      Scientist/Engineer - Computational Microscopy          110000.0   \n",
       "1521                               Data Science Manager          110000.0   \n",
       "1522   Data Scientist, Underwriting Customer Enablement          110000.0   \n",
       "1523                           Director of Data Science          110000.0   \n",
       "1524     Lead Data Scientist - Applied Machine Learning          110000.0   \n",
       "1525                     NRL Research Meteorologist Job          110000.0   \n",
       "1526                          Machine Learning Engineer          110000.0   \n",
       "\n",
       "      high_salary  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "5               0  \n",
       "6               0  \n",
       "7               0  \n",
       "8               0  \n",
       "9               0  \n",
       "10              0  \n",
       "11              0  \n",
       "12              0  \n",
       "13              0  \n",
       "14              0  \n",
       "15              0  \n",
       "16              0  \n",
       "17              0  \n",
       "18              0  \n",
       "19              0  \n",
       "20              0  \n",
       "21              0  \n",
       "22              0  \n",
       "23              0  \n",
       "24              0  \n",
       "25              0  \n",
       "26              0  \n",
       "27              0  \n",
       "28              0  \n",
       "29              0  \n",
       "...           ...  \n",
       "1497            1  \n",
       "1498            1  \n",
       "1499            1  \n",
       "1500            1  \n",
       "1501            1  \n",
       "1502            1  \n",
       "1503            1  \n",
       "1504            1  \n",
       "1505            1  \n",
       "1506            1  \n",
       "1507            1  \n",
       "1508            1  \n",
       "1509            1  \n",
       "1510            1  \n",
       "1511            1  \n",
       "1512            1  \n",
       "1513            1  \n",
       "1514            1  \n",
       "1515            1  \n",
       "1516            1  \n",
       "1517            1  \n",
       "1518            1  \n",
       "1519            1  \n",
       "1520            1  \n",
       "1521            1  \n",
       "1522            1  \n",
       "1523            1  \n",
       "1524            1  \n",
       "1525            1  \n",
       "1526            1  \n",
       "\n",
       "[1527 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove extraneous information. Some of the cities included what part of the city and \n",
    "# the postal codes. Because this information is inconsistent, this will help to standardize\n",
    "# the location data.\n",
    "loc_clean = [a[0:a.find(', CA')] for a in df_read.job_location]\n",
    "df_read[\"job_location\"] = loc_clean\n",
    "\n",
    "# In some cases, only \"California\" is listed as a city of work. Due to the lack of specificity,\n",
    "# we are dropping those rows.\n",
    "cali_index = df_read[df_read[\"job_location\"] == \"California\"].index\n",
    "df_read.drop(df_read.index[cali_index], inplace=True)\n",
    "df_read.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummy variables and encode \n",
    "city_dummies = pd.get_dummies(df_read.job_location)\n",
    "\n",
    "X_city = city_dummies\n",
    "y_city = df_read.high_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_city, y_city, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.647\n",
      "Cross Validation Score:\t0.646 ± 0.01\n"
     ]
    }
   ],
   "source": [
    "# Random forest classifier parameters and fit\n",
    "rfc = RandomForestClassifier(n_estimators=300)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test results and look at accuracy\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "acc = accuracy_score(y_test, rfc_pred)\n",
    "print \"Accuracy Score:\", acc.round(3)\n",
    "\n",
    "# Cross-validate on original data\n",
    "s = cross_val_score(rfc, X_city, y_city, cv=4, n_jobs=-1)\n",
    "print \"Cross Validation Score:\\t{:0.3} ± {:0.3}\".format(s.mean().round(3), s.std().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>median_salary</th>\n",
       "      <th>high_or_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>San Francisc</td>\n",
       "      <td>0.079411</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Mountain Vie</td>\n",
       "      <td>0.051302</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Cupertin</td>\n",
       "      <td>0.048274</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>El Segund</td>\n",
       "      <td>0.028959</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Woodlan</td>\n",
       "      <td>0.027742</td>\n",
       "      <td>102500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>San Jos</td>\n",
       "      <td>0.026564</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Orang</td>\n",
       "      <td>0.024382</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Fremon</td>\n",
       "      <td>0.022744</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Palo Alt</td>\n",
       "      <td>0.022337</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>San Ramo</td>\n",
       "      <td>0.021695</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Sunnyval</td>\n",
       "      <td>0.020718</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Stanfor</td>\n",
       "      <td>0.017933</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Novat</td>\n",
       "      <td>0.017201</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Moffett Fiel</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>77500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Rosemea</td>\n",
       "      <td>0.015205</td>\n",
       "      <td>102500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Santa An</td>\n",
       "      <td>0.014517</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Los Angele</td>\n",
       "      <td>0.014039</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Santa Monic</td>\n",
       "      <td>0.013925</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Murriet</td>\n",
       "      <td>0.013854</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Los Alto</td>\n",
       "      <td>0.013808</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature  importance  median_salary  high_or_low\n",
       "98   San Francisc    0.079411        80000.0            0\n",
       "62   Mountain Vie    0.051302        80000.0            0\n",
       "25       Cupertin    0.048274       110000.0            1\n",
       "29      El Segund    0.028959        60000.0            0\n",
       "130       Woodlan    0.027742       102500.0            1\n",
       "100       San Jos    0.026564        80000.0            0\n",
       "70          Orang    0.024382        95000.0            1\n",
       "34         Fremon    0.022744        80000.0            0\n",
       "74       Palo Alt    0.022337        80000.0            0\n",
       "104      San Ramo    0.021695        70000.0            0\n",
       "119      Sunnyval    0.020718        80000.0            0\n",
       "118       Stanfor    0.017933        60000.0            0\n",
       "67          Novat    0.017201        87500.0            1\n",
       "58   Moffett Fiel    0.015282        77500.0            0\n",
       "91        Rosemea    0.015205       102500.0            1\n",
       "105      Santa An    0.014517        80000.0            0\n",
       "49     Los Angele    0.014039        60000.0            0\n",
       "110   Santa Monic    0.013925        95000.0            1\n",
       "63        Murriet    0.013854        95000.0            1\n",
       "48       Los Alto    0.013808        95000.0            1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(rfc.feature_importances_,\n",
    "                                   index = X_city.columns).reset_index()\n",
    "feature_importances.columns = ['feature', 'importance']\n",
    "\n",
    "feature_medians = []\n",
    "for i in X_city.columns:\n",
    "    feature_medians.append(np.median(df_read[df_read.job_location == i].salary_estimated))\n",
    "\n",
    "feature_importances['median_salary'] = feature_medians\n",
    "feature_importances['high_or_low'] = [1 if i > 80000 else 0 for i in feature_importances.median_salary]\n",
    "\n",
    "feature_importances.sort_values('importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:800px;background:#ffff00;border:1px solid black;text-align:left;padding:8px;\">\n",
    "\n",
    "Cupertino seems to have the biggest impact on whether a salary is high, while San Francisco and Mountain View seem to influence the lower salary bandings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 4)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:800px;background:#ffff00;border:1px solid black;text-align:left;padding:8px;\">\n",
    "\n",
    "\n",
    "<p>\n",
    "Due to the number of words present for job summaries, we need something a bit more heavy duty than dummy coding. For the following sections, we \n",
    "utilize <b>CountVectorizer</b> to look at word frequencies. We do this for \n",
    "job titles as well afterwards.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_w_desc = df_read.copy(deep=False)\n",
    "\n",
    "X_summ = salaries_w_desc['job_summary']\n",
    "y_summ = salaries_w_desc['high_salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exclude standard stop words from sk-learn\n",
    "cv = CountVectorizer(stop_words=\"english\")\n",
    "cv.fit(X_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Densify the table otherwise we would be looking at many, many features\n",
    "X_summ_trans = pd.DataFrame(cv.transform(X_summ).todense(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.asmatrix(X_summ_trans), y_summ, test_size=0.3,\n",
    "                                                    stratify=y_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data           2540\n",
       "scientists      539\n",
       "scientist       431\n",
       "experience      328\n",
       "team            258\n",
       "analysis        227\n",
       "engineers       205\n",
       "learning        190\n",
       "science         178\n",
       "work            175\n",
       "machine         173\n",
       "product         147\n",
       "research        131\n",
       "analytics       130\n",
       "read            122\n",
       "looking         116\n",
       "working         108\n",
       "large           104\n",
       "big             104\n",
       "design          104\n",
       "senior          103\n",
       "development      93\n",
       "sets             86\n",
       "management       86\n",
       "algorithms       82\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = X_summ_trans.sum(axis=0)\n",
    "word_counts.sort_values(ascending = False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.636\n",
      "Cross Validation Score: 0.659 ± 0.029\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(300)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "acc = accuracy_score(y_test, rfc_pred)\n",
    "print \"Accuracy Score:\", acc.round(3)\n",
    "\n",
    "s = cross_val_score(rfc, X_summ_trans.as_matrix(), y_summ.as_matrix(), cv=4, n_jobs=-1)\n",
    "print \"Cross Validation Score: {:0.3} ± {:0.3}\".format(s.mean().round(3), s.std().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:800px;background:#ffff00;border:1px solid black;text-align:left;padding:8px;\">\n",
    "\n",
    "Overall, not bad. Remember we are looking at a baseline of 50% (high or low salary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GuangYi/anaconda/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/GuangYi/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>median_salary</th>\n",
       "      <th>mean_salary</th>\n",
       "      <th>over_or_under</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2436</th>\n",
       "      <td>read</td>\n",
       "      <td>0.019338</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>85664.062500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>data</td>\n",
       "      <td>0.012187</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>78854.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2630</th>\n",
       "      <td>science</td>\n",
       "      <td>0.007611</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>81445.783133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>team</td>\n",
       "      <td>0.006767</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>80300.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>scientists</td>\n",
       "      <td>0.006333</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>79591.633466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>experience</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>80729.483283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635</th>\n",
       "      <td>scientist</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>78763.570567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>building</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>91818.181818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>supporting</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>94090.909091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>business</td>\n",
       "      <td>0.004896</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>83716.216216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>learning</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>82500.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>big</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>82938.144330</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>work</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>80360.360360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>machine</td>\n",
       "      <td>0.004627</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>83151.515152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>distributed</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>88333.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>analysts</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>89000.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>engineers</td>\n",
       "      <td>0.004343</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>78894.472362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>analysis</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>76571.428571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>models</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>85111.111111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>engineering</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>80769.230769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature  importance  median_salary   mean_salary  over_or_under\n",
       "2436         read    0.019338        80000.0  85664.062500              0\n",
       "779          data    0.012187        80000.0  78854.166667              0\n",
       "2630      science    0.007611        80000.0  81445.783133              0\n",
       "2959         team    0.006767        80000.0  80300.000000              0\n",
       "2639   scientists    0.006333        80000.0  79591.633466              0\n",
       "1122   experience    0.005689        80000.0  80729.483283              0\n",
       "2635    scientist    0.005051        80000.0  78763.570567              0\n",
       "412      building    0.005001        95000.0  91818.181818              1\n",
       "2913   supporting    0.004980        95000.0  94090.909091              1\n",
       "417      business    0.004896        80000.0  83716.216216              0\n",
       "1698     learning    0.004801        80000.0  82500.000000              0\n",
       "356           big    0.004782        80000.0  82938.144330              0\n",
       "3205         work    0.004762        80000.0  80360.360360              0\n",
       "1765      machine    0.004627        80000.0  83151.515152              0\n",
       "914   distributed    0.004491        95000.0  88333.333333              1\n",
       "172      analysts    0.004375        95000.0  89000.000000              1\n",
       "1040    engineers    0.004343        80000.0  78894.472362              0\n",
       "170      analysis    0.004143        60000.0  76571.428571              0\n",
       "1904       models    0.003788        95000.0  85111.111111              1\n",
       "1038  engineering    0.003594        80000.0  80769.230769              0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(rfc.feature_importances_,\n",
    "                                   index = X_summ_trans.columns).reset_index()\n",
    "feature_importances.columns = ['feature', 'importance']\n",
    "\n",
    "feature_medians = []\n",
    "feature_means = []\n",
    "for i in X_summ_trans.columns:\n",
    "    feature_medians.append(np.median(salaries_w_desc[salaries_w_desc['job_summary'].str.lower().str.contains(i)].salary_estimated))\n",
    "    feature_means.append(np.mean(salaries_w_desc[salaries_w_desc['job_summary'].str.lower().str.contains(i)].salary_estimated))\n",
    "\n",
    "\n",
    "feature_importances['median_salary'] = feature_medians\n",
    "feature_importances['mean_salary'] = feature_means\n",
    "feature_importances['over_or_under'] = [1 if i > 80000 else 0 for i in feature_importances['median_salary']]\n",
    "\n",
    "feature_importances.sort_values('importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3231, 5)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salaries_w_desc = df_read.copy(deep=False)\n",
    "\n",
    "X_title = salaries_w_desc['job_title']\n",
    "y_title = salaries_w_desc['high_salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words=\"english\")\n",
    "cv.fit(X_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_title_trans = pd.DataFrame(cv.transform(X_title).todense(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_title_trans, y_title, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.606\n",
      "Cross Validation Score: 0.626 ± 0.024\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(300)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "acc = accuracy_score(y_test, rfc_pred)\n",
    "print \"Accuracy Score:\", acc.round(3)\n",
    "\n",
    "s = cross_val_score(rfc, X_title_trans.as_matrix(), y_title.as_matrix(), cv=4, n_jobs=-1)\n",
    "print \"Cross Validation Score: {:0.3} ± {:0.3}\".format(s.mean().round(3), s.std().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>median_salary</th>\n",
       "      <th>mean_salary</th>\n",
       "      <th>over_or_under</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>data</td>\n",
       "      <td>0.036019</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>82282.157676</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>senior</td>\n",
       "      <td>0.029814</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>80948.275862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>engineer</td>\n",
       "      <td>0.024205</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>82097.560976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>scientist</td>\n",
       "      <td>0.023599</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>78033.613445</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>learning</td>\n",
       "      <td>0.020889</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>84803.370787</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>sr</td>\n",
       "      <td>0.020122</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>81170.212766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>machine</td>\n",
       "      <td>0.019854</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>85343.750000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>research</td>\n",
       "      <td>0.018788</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>74444.444444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>software</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>82544.910180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>principal</td>\n",
       "      <td>0.013455</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>81515.151515</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>lead</td>\n",
       "      <td>0.012993</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>79112.903226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>analytics</td>\n",
       "      <td>0.012723</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>81811.594203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>manager</td>\n",
       "      <td>0.012533</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>79219.858156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>director</td>\n",
       "      <td>0.011825</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>82988.505747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>product</td>\n",
       "      <td>0.011108</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>81103.896104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>analyst</td>\n",
       "      <td>0.009802</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>71861.702128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>science</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>80317.460317</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>development</td>\n",
       "      <td>0.009423</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>80217.391304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>platform</td>\n",
       "      <td>0.009056</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>84200.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>stack</td>\n",
       "      <td>0.008713</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>78888.888889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  importance  median_salary   mean_salary  over_or_under\n",
       "227         data    0.036019        80000.0  82282.157676              0\n",
       "765       senior    0.029814        80000.0  80948.275862              0\n",
       "301     engineer    0.024205        80000.0  82097.560976              0\n",
       "751    scientist    0.023599        80000.0  78033.613445              0\n",
       "489     learning    0.020889        95000.0  84803.370787              1\n",
       "813           sr    0.020122        80000.0  81170.212766              0\n",
       "503      machine    0.019854        95000.0  85343.750000              1\n",
       "725     research    0.018788        60000.0  74444.444444              0\n",
       "791     software    0.017700        80000.0  82544.910180              0\n",
       "669    principal    0.013455        80000.0  81515.151515              0\n",
       "486         lead    0.012993        80000.0  79112.903226              0\n",
       "54     analytics    0.012723        80000.0  81811.594203              0\n",
       "505      manager    0.012533        80000.0  79219.858156              0\n",
       "255     director    0.011825        80000.0  82988.505747              0\n",
       "677      product    0.011108        80000.0  81103.896104              0\n",
       "50       analyst    0.009802        60000.0  71861.702128              0\n",
       "748      science    0.009495        80000.0  80317.460317              0\n",
       "243  development    0.009423        80000.0  80217.391304              0\n",
       "648     platform    0.009056        95000.0  84200.000000              1\n",
       "816        stack    0.008713        80000.0  78888.888889              0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(rfc.feature_importances_,\n",
    "                                   index = X_title_trans.columns).reset_index()\n",
    "feature_importances.columns = ['feature', 'importance']\n",
    "\n",
    "feature_medians = []\n",
    "feature_means = []\n",
    "for i in X_title_trans.columns:\n",
    "    feature_medians.append(np.median(salaries_w_desc[salaries_w_desc[\"job_title\"].str.lower().str.contains(i)].salary_estimated))\n",
    "    feature_means.append(np.mean(salaries_w_desc[salaries_w_desc[\"job_title\"].str.lower().str.contains(i)].salary_estimated))\n",
    "\n",
    "\n",
    "feature_importances['median_salary'] = feature_medians\n",
    "feature_importances['mean_salary'] = feature_means\n",
    "feature_importances['over_or_under'] = [1 if i > 80000 else 0 for i in feature_importances.median_salary]\n",
    "\n",
    "feature_importances.sort_values('importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(930, 5)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Title CV, Summary CV, and Location CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salaries_w_desc = df_read.copy(deep=False).reset_index(drop=True)\n",
    "city_dummies = pd.get_dummies(df_read.job_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = pd.concat([city_dummies.reset_index(drop=True), \n",
    "               X_title_trans.reset_index(drop=True), \n",
    "               X_summ_trans.reset_index(drop=True)], axis=1)\n",
    "y = salaries_w_desc.high_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1527, 4293)\n",
      "(1527,)\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.675381\n",
      "Cross Validation Score: 0.675 ± 0.02\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(300)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "acc = accuracy_score(y_test, rfc_pred)\n",
    "print \"Accuracy Score:\", acc.round(6)\n",
    "\n",
    "s = cross_val_score(rfc, X, y, cv=4, n_jobs=-1)\n",
    "print \"Cross Validation Score: {:0.3} ± {:0.3}\".format(s.mean().round(3), s.std().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:800px;background:#ffff00;border:1px solid black;text-align:left;padding:8px;\">\n",
    "\n",
    "So many calculations for something that's 17% better than chance? Maybe we should try looking at something else..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agoura Hill</td>\n",
       "      <td>1.206920e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alameda Harbo</td>\n",
       "      <td>3.207228e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alhambr</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aliso Viej</td>\n",
       "      <td>2.396266e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bakersfiel</td>\n",
       "      <td>3.150329e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Belmon</td>\n",
       "      <td>3.838838e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Berkele</td>\n",
       "      <td>5.064478e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Beverly Hill</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bre</td>\n",
       "      <td>6.172078e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Brisban</td>\n",
       "      <td>1.672762e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Burban</td>\n",
       "      <td>7.783598e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Burlingam</td>\n",
       "      <td>2.169199e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Calabasa</td>\n",
       "      <td>2.711446e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Californ</td>\n",
       "      <td>3.621944e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Camarill</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Campbel</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Canoga Par</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Carlsba</td>\n",
       "      <td>1.975144e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chic</td>\n",
       "      <td>1.115123e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Clovi</td>\n",
       "      <td>1.133848e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Colto</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Concor</td>\n",
       "      <td>5.436072e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Contra Costa Count</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Costa Mes</td>\n",
       "      <td>1.360251e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Culver Cit</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Cupertin</td>\n",
       "      <td>1.532735e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Cypres</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Davi</td>\n",
       "      <td>2.885818e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Duart</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>El Segund</td>\n",
       "      <td>1.528694e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4263</th>\n",
       "      <td>wireless</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>wirelessly</td>\n",
       "      <td>2.022401e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>womply</td>\n",
       "      <td>4.633147e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>word</td>\n",
       "      <td>7.410574e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>work</td>\n",
       "      <td>3.541668e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>workable</td>\n",
       "      <td>6.085424e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>workbooks</td>\n",
       "      <td>3.917377e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>workday</td>\n",
       "      <td>1.272840e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>worked</td>\n",
       "      <td>2.406019e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>worker</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>workflows</td>\n",
       "      <td>2.664102e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>workforce</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>working</td>\n",
       "      <td>2.410983e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>workload</td>\n",
       "      <td>8.849224e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277</th>\n",
       "      <td>workplace</td>\n",
       "      <td>1.488397e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4278</th>\n",
       "      <td>works</td>\n",
       "      <td>4.349922e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>world</td>\n",
       "      <td>1.480318e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>wrangling</td>\n",
       "      <td>2.295710e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>write</td>\n",
       "      <td>2.173026e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>writing</td>\n",
       "      <td>2.562590e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>written</td>\n",
       "      <td>1.215552e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284</th>\n",
       "      <td>xgds</td>\n",
       "      <td>6.874923e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>xml</td>\n",
       "      <td>2.136743e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>year</td>\n",
       "      <td>2.265827e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>years</td>\n",
       "      <td>2.148114e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4288</th>\n",
       "      <td>york</td>\n",
       "      <td>4.616800e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4289</th>\n",
       "      <td>youll</td>\n",
       "      <td>6.117634e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4290</th>\n",
       "      <td>zipongo</td>\n",
       "      <td>2.020632e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4291</th>\n",
       "      <td>zoom</td>\n",
       "      <td>2.514160e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4292</th>\n",
       "      <td>zymergen</td>\n",
       "      <td>1.591015e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4293 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature    importance\n",
       "0            Agoura Hill  1.206920e-05\n",
       "1          Alameda Harbo  3.207228e-04\n",
       "2                Alhambr  0.000000e+00\n",
       "3             Aliso Viej  2.396266e-04\n",
       "4             Bakersfiel  3.150329e-06\n",
       "5                 Belmon  3.838838e-07\n",
       "6                Berkele  5.064478e-05\n",
       "7           Beverly Hill  0.000000e+00\n",
       "8                    Bre  6.172078e-06\n",
       "9                Brisban  1.672762e-05\n",
       "10                Burban  7.783598e-05\n",
       "11             Burlingam  2.169199e-04\n",
       "12              Calabasa  2.711446e-05\n",
       "13              Californ  3.621944e-04\n",
       "14              Camarill  0.000000e+00\n",
       "15               Campbel  0.000000e+00\n",
       "16            Canoga Par  0.000000e+00\n",
       "17               Carlsba  1.975144e-04\n",
       "18                  Chic  1.115123e-05\n",
       "19                 Clovi  1.133848e-05\n",
       "20                 Colto  0.000000e+00\n",
       "21                Concor  5.436072e-05\n",
       "22    Contra Costa Count  0.000000e+00\n",
       "23             Costa Mes  1.360251e-04\n",
       "24            Culver Cit  0.000000e+00\n",
       "25              Cupertin  1.532735e-03\n",
       "26                Cypres  0.000000e+00\n",
       "27                  Davi  2.885818e-05\n",
       "28                 Duart  0.000000e+00\n",
       "29             El Segund  1.528694e-03\n",
       "...                  ...           ...\n",
       "4263            wireless  0.000000e+00\n",
       "4264          wirelessly  2.022401e-04\n",
       "4265              womply  4.633147e-05\n",
       "4266                word  7.410574e-06\n",
       "4267                work  3.541668e-03\n",
       "4268            workable  6.085424e-06\n",
       "4269           workbooks  3.917377e-05\n",
       "4270             workday  1.272840e-05\n",
       "4271              worked  2.406019e-04\n",
       "4272              worker  0.000000e+00\n",
       "4273           workflows  2.664102e-04\n",
       "4274           workforce  0.000000e+00\n",
       "4275             working  2.410983e-03\n",
       "4276            workload  8.849224e-06\n",
       "4277           workplace  1.488397e-04\n",
       "4278               works  4.349922e-04\n",
       "4279               world  1.480318e-03\n",
       "4280           wrangling  2.295710e-04\n",
       "4281               write  2.173026e-04\n",
       "4282             writing  2.562590e-04\n",
       "4283             written  1.215552e-04\n",
       "4284                xgds  6.874923e-06\n",
       "4285                 xml  2.136743e-04\n",
       "4286                year  2.265827e-04\n",
       "4287               years  2.148114e-03\n",
       "4288                york  4.616800e-06\n",
       "4289               youll  6.117634e-05\n",
       "4290             zipongo  2.020632e-05\n",
       "4291                zoom  2.514160e-04\n",
       "4292            zymergen  1.591015e-05\n",
       "\n",
       "[4293 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(rfc.feature_importances_,\n",
    "                                   index = X.columns).reset_index()\n",
    "feature_importances.columns = ['feature', 'importance']\n",
    "df_read.reset_index(drop=True, inplace=True)\n",
    "salaries_w_desc.reset_index(drop=True, inplace=True)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>median_salary</th>\n",
       "      <th>over_or_under</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>read</td>\n",
       "      <td>0.024689</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>data</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>data</td>\n",
       "      <td>0.009330</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>San Francisc</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>machine</td>\n",
       "      <td>0.006542</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>engineer</td>\n",
       "      <td>0.005656</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>learning</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3692</th>\n",
       "      <td>science</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>large</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>scientist</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>building</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>scientist</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3701</th>\n",
       "      <td>scientists</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>experience</td>\n",
       "      <td>0.004041</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>laboratory</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4021</th>\n",
       "      <td>team</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>senior</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>learning</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>business</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>machine</td>\n",
       "      <td>0.003542</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature  importance  median_salary  over_or_under\n",
       "3498          read    0.024689        80000.0              0\n",
       "1841          data    0.010610        80000.0              0\n",
       "359           data    0.009330        80000.0              0\n",
       "98    San Francisc    0.007722        80000.0              0\n",
       "635        machine    0.006542        95000.0              1\n",
       "433       engineer    0.005656        80000.0              0\n",
       "621       learning    0.005554        95000.0              1\n",
       "3692       science    0.004637        80000.0              0\n",
       "2740         large    0.004566        80000.0              0\n",
       "883      scientist    0.004448        80000.0              0\n",
       "1474      building    0.004317        95000.0              1\n",
       "3697     scientist    0.004197        80000.0              0\n",
       "3701    scientists    0.004117        80000.0              0\n",
       "2184    experience    0.004041        80000.0              0\n",
       "2732    laboratory    0.003982        60000.0              0\n",
       "4021          team    0.003891        80000.0              0\n",
       "897         senior    0.003837        80000.0              0\n",
       "2760      learning    0.003717        80000.0              0\n",
       "1479      business    0.003640        80000.0              0\n",
       "2827       machine    0.003542        80000.0              0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_medians = []\n",
    "for i in city_dummies.columns:\n",
    "    feature_medians.append(np.median(salaries_w_desc[salaries_w_desc.job_location == i].salary_estimated))\n",
    "    \n",
    "for i in X_title_trans.columns:\n",
    "    feature_medians.append(np.median(salaries_w_desc[salaries_w_desc[\"job_title\"].str.lower().str.contains(i)].salary_estimated))\n",
    "\n",
    "for i in X_summ_trans.columns:\n",
    "    feature_medians.append(np.median(salaries_w_desc[salaries_w_desc['job_summary'].str.lower().str.contains(i)].salary_estimated))\n",
    "\n",
    "feature_importances['median_salary'] = feature_medians\n",
    "feature_importances['over_or_under'] = [1 if i > 80000 else 0 for i in feature_importances.median_salary]\n",
    "\n",
    "feature_importances.sort_values('importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:800px;background:#ffff00;border:1px solid black;text-align:left;padding:8px;\">\n",
    "\n",
    "We repeat the same basic cleaning as above for a fresh copy of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_estimated</th>\n",
       "      <th>high_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart eCommerce</td>\n",
       "      <td>San Bruno</td>\n",
       "      <td>Data scientists, front and back-end engineers, product managers, and web and UX/UI teams collaborate alongside e-commerce experts to envision, prototype, and...</td>\n",
       "      <td>Director, Retail Learning &amp; Development</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>Menlo Park</td>\n",
       "      <td>Work with engineering, data science, and design teams to build innovative data products and supporting infrastructure....</td>\n",
       "      <td>Product Manager, Advanced Network Planning</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kaiser Permanente</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>He or she will manage a team of analysts, data scientists and statisticians, have understanding and appreciation of analytical processes and business process...</td>\n",
       "      <td>Senior Manager Decision Support</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PaxVax</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>Good data anaylsis skills. Is seeking a Scientist to join the Process Development and Clinical Production teams focused on vaccine development from preclinical...</td>\n",
       "      <td>Scientist, Process Development - Upstream</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Aerospace Corporation</td>\n",
       "      <td>El Segundo</td>\n",
       "      <td>Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world. Bring fresh ideas from all areas, including distributed...</td>\n",
       "      <td>Associate Software Engineer</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   comp_name job_location  \\\n",
       "0          Walmart eCommerce    San Bruno   \n",
       "1                   Facebook   Menlo Park   \n",
       "2          Kaiser Permanente      Oakland   \n",
       "3                     PaxVax    San Diego   \n",
       "4  The Aerospace Corporation   El Segundo   \n",
       "\n",
       "                                                                                                                                                          job_summary  \\\n",
       "0    Data scientists, front and back-end engineers, product managers, and web and UX/UI teams collaborate alongside e-commerce experts to envision, prototype, and...   \n",
       "1                                           Work with engineering, data science, and design teams to build innovative data products and supporting infrastructure....   \n",
       "2    He or she will manage a team of analysts, data scientists and statisticians, have understanding and appreciation of analytical processes and business process...   \n",
       "3  Good data anaylsis skills. Is seeking a Scientist to join the Process Development and Clinical Production teams focused on vaccine development from preclinical...   \n",
       "4   Our state-of-the-art laboratory facilities are staffed by some of the leading scientists in the world. Bring fresh ideas from all areas, including distributed...   \n",
       "\n",
       "                                    job_title  salary_estimated  high_salary  \n",
       "0     Director, Retail Learning & Development           60000.0            0  \n",
       "1  Product Manager, Advanced Network Planning           60000.0            0  \n",
       "2             Senior Manager Decision Support           60000.0            0  \n",
       "3   Scientist, Process Development - Upstream           60000.0            0  \n",
       "4                 Associate Software Engineer           60000.0            0  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_read.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_rmodel = df_read[[\"comp_name\", \"job_location\", \"salary_estimated\", \"high_salary\"]]\n",
    "df_rmodel.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1527, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rmodel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GuangYi/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>salary_estimated</th>\n",
       "      <th>high_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart eCommerce</td>\n",
       "      <td>San Bruno, CA 94066</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>Menlo Park, CA</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kaiser Permanente</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PaxVax</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Aerospace Corporation</td>\n",
       "      <td>El Segundo, CA 90245</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Walmart eCommerce</td>\n",
       "      <td>San Bruno, CA 94066</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BeiGene</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ascent Services Group</td>\n",
       "      <td>South San Francisco, CA</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Remind</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>First American</td>\n",
       "      <td>Agoura Hills, CA 91301</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rocket Lawyer</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Uber</td>\n",
       "      <td>San Francisco, CA 94103 (South Of Market area)</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Viatouch Media</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Osaro</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Immucor, Inc</td>\n",
       "      <td>Mountain View, CA 94043</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Siemens</td>\n",
       "      <td>Berkeley, CA</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Brainworks</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Qubol</td>\n",
       "      <td>Santa Clara, CA</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Zymergen</td>\n",
       "      <td>Emeryville, CA 94608</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>California Institute of Technology</td>\n",
       "      <td>Pasadena, CA 91125</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Staples</td>\n",
       "      <td>San Jose, CA 95113 (Downtown area)</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ayasdi</td>\n",
       "      <td>Menlo Park, CA 94025</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Stanford University</td>\n",
       "      <td>Stanford, CA 94305</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Roche</td>\n",
       "      <td>Belmont, CA</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Roche</td>\n",
       "      <td>Belmont, CA</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Osaro</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Ardelyx</td>\n",
       "      <td>Fremont, CA 94555 (Northgate area)</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Celgene Corporation</td>\n",
       "      <td>San Diego, CA 92121</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Illumina</td>\n",
       "      <td>San Diego, CA 92101</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Celgene Corporation</td>\n",
       "      <td>San Diego, CA 92121</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>FabFitFun</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>Wish</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>GoPro Careers Page</td>\n",
       "      <td>San Mateo, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>LendUp</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>Color Genomics</td>\n",
       "      <td>Burlingame, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>Grand Rounds</td>\n",
       "      <td>San Francisco, CA 94107 (South Of Market area)</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>Quora</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>Boehringer Ingelheim</td>\n",
       "      <td>Fremont, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>Jazz Pharmaceuticals</td>\n",
       "      <td>Palo Alto, CA 94304</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>Netflix</td>\n",
       "      <td>Los Gatos, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>Proofpoint</td>\n",
       "      <td>Sunnyvale, CA 94089</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>View, Inc.</td>\n",
       "      <td>Milpitas, CA 95035</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>KLA-Tencor</td>\n",
       "      <td>Milpitas, CA 95035</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>Blue River Technology</td>\n",
       "      <td>Sunnyvale, CA 94085</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>Twitch</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>LogMeIn, Inc.</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>Pfizer</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>10x Genomics</td>\n",
       "      <td>Pleasanton, CA 94566</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>Southern California Edison</td>\n",
       "      <td>Rosemead, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>Bossanova Robotics</td>\n",
       "      <td>San Francisco, CA 94107 (South Of Market area)</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>Modesto, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>SAIC</td>\n",
       "      <td>Monterey, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>Walmart eCommerce</td>\n",
       "      <td>San Bruno, CA 94066</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>Chan Zuckerberg Biohub</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>Udacity, Inc.</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>Symantec</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>TrueAccord</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>Life360</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>SAIC</td>\n",
       "      <td>Monterey, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>HomeLight</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1513 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               comp_name  \\\n",
       "0                      Walmart eCommerce   \n",
       "1                               Facebook   \n",
       "2                      Kaiser Permanente   \n",
       "3                                 PaxVax   \n",
       "4              The Aerospace Corporation   \n",
       "5                      Walmart eCommerce   \n",
       "6                                BeiGene   \n",
       "7                  Ascent Services Group   \n",
       "8                                 Remind   \n",
       "9                         First American   \n",
       "10                         Rocket Lawyer   \n",
       "11                                  Uber   \n",
       "12                        Viatouch Media   \n",
       "13                                 Osaro   \n",
       "14                          Immucor, Inc   \n",
       "15                               Siemens   \n",
       "16                            Brainworks   \n",
       "17                                 Qubol   \n",
       "18                              Zymergen   \n",
       "19    California Institute of Technology   \n",
       "20                               Staples   \n",
       "21                                Ayasdi   \n",
       "22                   Stanford University   \n",
       "23                                 Roche   \n",
       "24                                 Roche   \n",
       "25                                 Osaro   \n",
       "26                               Ardelyx   \n",
       "27                   Celgene Corporation   \n",
       "28                              Illumina   \n",
       "29                   Celgene Corporation   \n",
       "...                                  ...   \n",
       "1483                           FabFitFun   \n",
       "1484                                Wish   \n",
       "1485                  GoPro Careers Page   \n",
       "1486                              LendUp   \n",
       "1487                      Color Genomics   \n",
       "1488                        Grand Rounds   \n",
       "1489                               Quora   \n",
       "1490                Boehringer Ingelheim   \n",
       "1491                Jazz Pharmaceuticals   \n",
       "1492                             Netflix   \n",
       "1493                          Proofpoint   \n",
       "1494                          View, Inc.   \n",
       "1495                          KLA-Tencor   \n",
       "1496               Blue River Technology   \n",
       "1497                              Twitch   \n",
       "1498                       LogMeIn, Inc.   \n",
       "1499                              Pfizer   \n",
       "1500                        10x Genomics   \n",
       "1501          Southern California Edison   \n",
       "1502                  Bossanova Robotics   \n",
       "1503                    All-In Analytics   \n",
       "1504                                SAIC   \n",
       "1505                   Walmart eCommerce   \n",
       "1506              Chan Zuckerberg Biohub   \n",
       "1507                       Udacity, Inc.   \n",
       "1508                            Symantec   \n",
       "1509                          TrueAccord   \n",
       "1510                             Life360   \n",
       "1511                                SAIC   \n",
       "1512                           HomeLight   \n",
       "\n",
       "                                        job_location  salary_estimated  \\\n",
       "0                                San Bruno, CA 94066           60000.0   \n",
       "1                                     Menlo Park, CA           60000.0   \n",
       "2                                        Oakland, CA           60000.0   \n",
       "3                                      San Diego, CA           60000.0   \n",
       "4                               El Segundo, CA 90245           60000.0   \n",
       "5                                San Bruno, CA 94066           60000.0   \n",
       "6                                  San Francisco, CA           60000.0   \n",
       "7                            South San Francisco, CA           60000.0   \n",
       "8                                  San Francisco, CA           60000.0   \n",
       "9                             Agoura Hills, CA 91301           60000.0   \n",
       "10                                 San Francisco, CA           60000.0   \n",
       "11    San Francisco, CA 94103 (South Of Market area)           60000.0   \n",
       "12                                     San Diego, CA           60000.0   \n",
       "13                                 San Francisco, CA           60000.0   \n",
       "14                           Mountain View, CA 94043           60000.0   \n",
       "15                                      Berkeley, CA           60000.0   \n",
       "16                                       Oakland, CA           60000.0   \n",
       "17                                   Santa Clara, CA           60000.0   \n",
       "18                              Emeryville, CA 94608           60000.0   \n",
       "19                                Pasadena, CA 91125           60000.0   \n",
       "20                San Jose, CA 95113 (Downtown area)           60000.0   \n",
       "21                              Menlo Park, CA 94025           60000.0   \n",
       "22                                Stanford, CA 94305           60000.0   \n",
       "23                                       Belmont, CA           60000.0   \n",
       "24                                       Belmont, CA           60000.0   \n",
       "25                                 San Francisco, CA           60000.0   \n",
       "26                Fremont, CA 94555 (Northgate area)           60000.0   \n",
       "27                               San Diego, CA 92121           60000.0   \n",
       "28                               San Diego, CA 92101           60000.0   \n",
       "29                               San Diego, CA 92121           60000.0   \n",
       "...                                              ...               ...   \n",
       "1483                                 Los Angeles, CA          110000.0   \n",
       "1484                               San Francisco, CA          110000.0   \n",
       "1485                                   San Mateo, CA          110000.0   \n",
       "1486                               San Francisco, CA          110000.0   \n",
       "1487                                  Burlingame, CA          110000.0   \n",
       "1488  San Francisco, CA 94107 (South Of Market area)          110000.0   \n",
       "1489                               Mountain View, CA          110000.0   \n",
       "1490                                     Fremont, CA          110000.0   \n",
       "1491                             Palo Alto, CA 94304          110000.0   \n",
       "1492                                   Los Gatos, CA          110000.0   \n",
       "1493                             Sunnyvale, CA 94089          110000.0   \n",
       "1494                              Milpitas, CA 95035          110000.0   \n",
       "1495                              Milpitas, CA 95035          110000.0   \n",
       "1496                             Sunnyvale, CA 94085          110000.0   \n",
       "1497                               San Francisco, CA          110000.0   \n",
       "1498                               Mountain View, CA          110000.0   \n",
       "1499                               San Francisco, CA          110000.0   \n",
       "1500                            Pleasanton, CA 94566          110000.0   \n",
       "1501                                    Rosemead, CA          110000.0   \n",
       "1502  San Francisco, CA 94107 (South Of Market area)          110000.0   \n",
       "1503                                     Modesto, CA          110000.0   \n",
       "1504                                    Monterey, CA          110000.0   \n",
       "1505                             San Bruno, CA 94066          110000.0   \n",
       "1506                               San Francisco, CA          110000.0   \n",
       "1507                               San Francisco, CA          110000.0   \n",
       "1508                               Mountain View, CA          110000.0   \n",
       "1509                               San Francisco, CA          110000.0   \n",
       "1510                               San Francisco, CA          110000.0   \n",
       "1511                                    Monterey, CA          110000.0   \n",
       "1512                               San Francisco, CA          110000.0   \n",
       "\n",
       "      high_salary  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "5               0  \n",
       "6               0  \n",
       "7               0  \n",
       "8               0  \n",
       "9               0  \n",
       "10              0  \n",
       "11              0  \n",
       "12              0  \n",
       "13              0  \n",
       "14              0  \n",
       "15              0  \n",
       "16              0  \n",
       "17              0  \n",
       "18              0  \n",
       "19              0  \n",
       "20              0  \n",
       "21              0  \n",
       "22              0  \n",
       "23              0  \n",
       "24              0  \n",
       "25              0  \n",
       "26              0  \n",
       "27              0  \n",
       "28              0  \n",
       "29              0  \n",
       "...           ...  \n",
       "1483            1  \n",
       "1484            1  \n",
       "1485            1  \n",
       "1486            1  \n",
       "1487            1  \n",
       "1488            1  \n",
       "1489            1  \n",
       "1490            1  \n",
       "1491            1  \n",
       "1492            1  \n",
       "1493            1  \n",
       "1494            1  \n",
       "1495            1  \n",
       "1496            1  \n",
       "1497            1  \n",
       "1498            1  \n",
       "1499            1  \n",
       "1500            1  \n",
       "1501            1  \n",
       "1502            1  \n",
       "1503            1  \n",
       "1504            1  \n",
       "1505            1  \n",
       "1506            1  \n",
       "1507            1  \n",
       "1508            1  \n",
       "1509            1  \n",
       "1510            1  \n",
       "1511            1  \n",
       "1512            1  \n",
       "\n",
       "[1513 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cali_index = df_rmodel[df_rmodel[\"job_location\"] == \"California\"].index\n",
    "df_rmodel.drop(df_rmodel.index[cali_index], inplace=True)\n",
    "df_rmodel.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc_clean = [a[0:a.find(', CA')] for a in df_rmodel.job_location]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GuangYi/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_rmodel[\"job_location\"] = loc_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>salary_estimated</th>\n",
       "      <th>high_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart eCommerce</td>\n",
       "      <td>San Bruno</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>Menlo Park</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kaiser Permanente</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PaxVax</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Aerospace Corporation</td>\n",
       "      <td>El Segundo</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   comp_name job_location  salary_estimated  high_salary\n",
       "0          Walmart eCommerce    San Bruno           60000.0            0\n",
       "1                   Facebook   Menlo Park           60000.0            0\n",
       "2          Kaiser Permanente      Oakland           60000.0            0\n",
       "3                     PaxVax    San Diego           60000.0            0\n",
       "4  The Aerospace Corporation   El Segundo           60000.0            0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rmodel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "San Francisco             337\n",
       "San Diego                 112\n",
       "San Jose                   87\n",
       "Mountain View              69\n",
       "Santa Clara                66\n",
       "Palo Alto                  64\n",
       "South San Francisco        60\n",
       "Sunnyvale                  58\n",
       "Los Angeles                56\n",
       "El Segundo                 48\n",
       "Redwood City               44\n",
       "Irvine                     32\n",
       "Menlo Park                 27\n",
       "Emeryville                 25\n",
       "San Mateo                  21\n",
       "Livermore                  19\n",
       "San Bruno                  19\n",
       "Fremont                    16\n",
       "Pleasanton                 16\n",
       "Los Gatos                  15\n",
       "San Ramon                  14\n",
       "Foster City                13\n",
       "Thousand Oaks              13\n",
       "Santa Monica               13\n",
       "San Francisco Bay Area     10\n",
       "Pasadena                   10\n",
       "Stanford                    9\n",
       "Oakland                     9\n",
       "Cupertino                   9\n",
       "Hayward                     8\n",
       "                         ... \n",
       "San Bernardino              1\n",
       "Hollywood                   1\n",
       "Redding                     1\n",
       "Beverly Hills               1\n",
       "Santa Fe Springs            1\n",
       "Orinda                      1\n",
       "Salinas                     1\n",
       "Rancho Cordova              1\n",
       "Modesto                     1\n",
       "Huntington Beach            1\n",
       "French Camp                 1\n",
       "Sylmar                      1\n",
       "Colton                      1\n",
       "Pleasant Hill               1\n",
       "Fresno                      1\n",
       "Sonoma                      1\n",
       "Canoga Park                 1\n",
       "Merced                      1\n",
       "Redondo Beach               1\n",
       "Campbell                    1\n",
       "Folsom                      1\n",
       "Point Mugu NAWC             1\n",
       "Murrieta                    1\n",
       "Port Hueneme                1\n",
       "Alameda Harbor              1\n",
       "Napa                        1\n",
       "Valencia                    1\n",
       "Malibu                      1\n",
       "Culver City                 1\n",
       "Kentfield                   1\n",
       "Name: job_location, Length: 131, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rmodel[\"job_location\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df_rmodel[[\"comp_name\", \"job_location\"]]\n",
    "y = df_rmodel[\"high_salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish parameters for gridsearch on logistic regression\n",
    "gs_params = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'solver':['liblinear'],\n",
    "    'C':np.logspace(-5,0,100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr_gridsearch = GridSearchCV(lr, gs_params, cv=5, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   29.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': array([  1.00000e-05,   1.12332e-05, ...,   8.90215e-01,   1.00000e+00]), 'solver': ['liblinear']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.671388101983\n"
     ]
    }
   ],
   "source": [
    "print lr_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.030538555088334154, 'penalty': 'l1', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66740088105726869"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gs = lr_gridsearch.best_estimator_\n",
    "best_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:800px;background:#ffff00;border:1px solid black;text-align:left;padding:8px;\">\n",
    "Remember that the baseline is 50%, and our random forest gave us an accuracy of 67.53%.\n",
    "How does the model perform when given salary bands instead of high or low?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = df_rmodel[\"salary_estimated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': array([  1.00000e-05,   1.12332e-05, ...,   8.90215e-01,   1.00000e+00]), 'solver': ['liblinear']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.470254957507\n"
     ]
    }
   ],
   "source": [
    "print lr_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0000000000000001e-05, 'penalty': 'l1', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48458149779735682"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gs = lr_gridsearch.best_estimator_\n",
    "best_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:800px;background:#ffff00;border:1px solid black;text-align:left;padding:8px;\">\n",
    "\n",
    "Given that there are 4 salary bands, the base is 25%. This is not bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the job postings you scraped for part 1 (or potentially new job postings from a second round of scraping), identify features in the data related to job postings that can distinguish job titles from each other. There are a variety of interesting ways you can frame the target variable, for example:\n",
    "- What components of a job posting distinguish data scientists from other data jobs?\n",
    "- What features are important for distinguishing junior vs. senior positions?\n",
    "- Do the requirements for titles vary significantly with industry (e.g. healthcare vs. government)?\n",
    "\n",
    "You may end up making multiple classification models to tackle different questions. Be sure to clearly explain your hypotheses and framing, any feature engineering, and what your target variables are. The type of classification model you choose is up to you. Be sure to interpret your results and evaluate your models' performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second round of Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:800px;background:#ffff00;border:1px solid black;text-align:left;padding:8px;\">\n",
    "\n",
    "For this round of scraping, we used an exact search for \"Data Scientist\" with quotation marks, as opposed to the inital scraping which pulled any mention of \"data\" or \"scientist\" regardless of order.\n",
    "\n",
    "Since we are interested in what factors affect job title, this precision is more necessary.\n",
    "\n",
    "Otherwise, the analysis is basically identical to that of the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List various salary bandings for exact match \"data scientist\" jobs in California\n",
    "url_ca_exact_60 = 'https://www.indeed.com/jobs?q=%22Data+Scientist%22+$60,000&l=California&radius=50&jt=fulltime&sort='\n",
    "url_ca_exact_80 = 'https://www.indeed.com/jobs?q=%22Data+Scientist%22+$80,000&l=California&radius=50&jt=fulltime&sort='\n",
    "url_ca_exact_95 = 'https://www.indeed.com/jobs?q=%22Data+Scientist%22+$95,000&l=California&radius=50&jt=fulltime&sort='\n",
    "url_ca_exact_110 = 'https://www.indeed.com/jobs?q=%22Data+Scientist%22+$110,000&l=California&radius=50&jt=fulltime&sort='\n",
    "\n",
    "# Pre-establish the database\n",
    "df2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_title</th>\n",
       "      <th>listed_job_salary</th>\n",
       "      <th>salary_estimated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLARA analytics</td>\n",
       "      <td>Santa Clara, CA</td>\n",
       "      <td>\\nThe Data Scientist role involves working on all stages of the data science pipeline, from acquiring and assessing data, selecting appropriate models and...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shutterfly</td>\n",
       "      <td>Redwood City, CA</td>\n",
       "      <td>\\nThe Data Scientist will be responsible for designing and directing experiments and observational studies to optimize our customer acquisition and engagement...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lam Research</td>\n",
       "      <td>Fremont, CA 94538 (Irvington area)</td>\n",
       "      <td>\\nDefine data structures, evaluate data quality, perform appropriate data analyses using software such as Python and MATLAB....</td>\n",
       "      <td>Data Scientist 4</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRAIL, Inc.</td>\n",
       "      <td>Menlo Park, CA</td>\n",
       "      <td>\\nParticipate in data quality review activities and efforts to resolve data quality issues. Develop and manage interactive data visualization and analytic tools...</td>\n",
       "      <td>Senior Staff Clinical Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chatham Group</td>\n",
       "      <td>San Francisco, CA 94104 (Financial District area)</td>\n",
       "      <td>\\nDo you like data? Experience in data analysis, gaming, mobile applications, consulting, or business/financial analysis....</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>\\n$70,000 a year</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Petco</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>\\nThis role will supervise the assistant merchant managers and work very closely with the customer data scientist and manager business analytics....</td>\n",
       "      <td>Services Manager</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Jose, CA 95113 (Downtown area)</td>\n",
       "      <td>\\nA well-established retail company located in Silicon Valley is looking for a contract Senior Data Scientist to take on a role providing modeling, analysis, and...</td>\n",
       "      <td>Senior Data Scientist (Contract)</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>\\nA Series C Healthcare Startup Located in Palo Alto is on the seeking for a bold Mid-Level Data Scientist to join to the team....</td>\n",
       "      <td>Mid-level Data Scientist</td>\n",
       "      <td>\\n$130,000 - $165,000 a year</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Remind</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>\\nAnalyze data to identify trends and opportunities, surface actionable insights, and help teams set goals, forecasts and prioritization of initiatives....</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FullDeck</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>\\n2+ years of experience in data mining and/or data science. A flourishing digital media agency with high profile entertainment clients, has an immediate need for...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Brainworks</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>\\nOur client, a fast-growing, well-funded, ecommerce start-up is looking for a Data Scientist . You will assist in building a data driven culture by exploring the...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Atreca</td>\n",
       "      <td>Redwood City, CA 94063</td>\n",
       "      <td>\\nWe are looking for a Data Scientist who will help us use the information hidden in vast amounts of data to make smarter research decisions and discover novel...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Honest Company (Career Page)</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>\\nWe're currently looking to add another Data Scientist to our fantastic Data team. As a Data Scientist, you'll have the opportunity to inform business decisions...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Symantec</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>\\nData acquisition will require navigation of Hadoop, Spark, databases (SQL), 3rd party data sources and text processing....</td>\n",
       "      <td>Research Engineer/ Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NEURALINK</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>\\nExperience with biological data. Experience with time series data. Develop machine-learning techniques for decoding neural data in real time....</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Veeva</td>\n",
       "      <td>Pleasanton, CA</td>\n",
       "      <td>\\nCombine your love and knowledge of quantitative data analysis across large data sets with solid presentation skills Use statistical methods to derive new...</td>\n",
       "      <td>Data Scientist - Deep Learning</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SpaceX</td>\n",
       "      <td>Hawthorne, CA</td>\n",
       "      <td>\\nPerform exploratory data analysis, extract data from various sources, clean and aggregate data. The Data Science team is a new team in the Enterprise Data...</td>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mission Bio</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>\\nWe are seeking a highly-motivated Data Scientist I/II to provide analytical support of sequencing data from our proprietary single-cell genomics platform....</td>\n",
       "      <td>Data Scientist I/II</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>\\nData Scientist Specialist. Core Data Scientist team. Scientist Specialist manages, architects and analyzes big data in....</td>\n",
       "      <td>Data Scientist Specialist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>San Francisco, CA 94103 (South Of Market area)</td>\n",
       "      <td>\\nYou will build Twitter’s next-generation Tailored Audience Targeting platform, working closely with product managers, data scientist, and machine learning...</td>\n",
       "      <td>Software Engineer, Backend</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ZestFinance</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>\\nRecruit, motivate, and develop the best data scientist talent in the world. Experience developing real-time production data pipelines....</td>\n",
       "      <td>Director, Data Science</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Xiar Tech</td>\n",
       "      <td>Palo Alto, CA 94301 (Professorville area)</td>\n",
       "      <td>\\nData ScientistPalo Alto, CA6+monthsPlease look for local consultants only.We are looking for a Data Scientist with a large client – experience required is...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>\\nThe Data Scientist. Data Scientist Associate Principal. Statistical and machine learning models, data mining, unstructured data. Data Scientists in....</td>\n",
       "      <td>Data Scientist Associate Principal</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>General Electric</td>\n",
       "      <td>San Francisco, CA 94102 (Downtown area)</td>\n",
       "      <td>\\nYou will be working with world class data scientist, engineers, designers, and domain experts to support state-of-the-art AI and machine learning solutions...</td>\n",
       "      <td>Sr Software Engineer - DevOps</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Infolob Solutions Inc</td>\n",
       "      <td>San Francisco, CA 94112 (Outer Mission area)</td>\n",
       "      <td>\\nProvided by Dice Data Scientist, Spark, Scala, Python, Data Scientist. Senior Data ScientistLocation:. Looking for a strong Data Scientist with hands on...</td>\n",
       "      <td>Senior Data Scientist (Remote)</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>Concord, CA</td>\n",
       "      <td>\\nReporting, analytics, Data modeling, Data Structures and Algorithms. This person will be a key contributor to the Artificial Intelligence/Machine Learning...</td>\n",
       "      <td>Analytic Manager 4</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[24]7</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>\\nAnalyze application data. The Data Scientist will be responsible for continually improving 24/7’s premier voice applications....</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Activision</td>\n",
       "      <td>Foster City, CA</td>\n",
       "      <td>\\nAnd data transformations. Strong data visualization and. Scientist with strong analytical skills. Data visualizations and integrating with analytics APIs....</td>\n",
       "      <td>Data Scientist - Foster City, CA</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Mode</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>\\nComfort with SQL and web-based technologies—You don't need be an engineer or data scientist, but you should know how to write a query and comfortable learning...</td>\n",
       "      <td>Customer Support Analyst</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>San Jose, CA 95113 (Downtown area)</td>\n",
       "      <td>\\nSome work with Big Data technologies (Spark). 2 + years of experience in Data Science. At the moment, they are looking to further build their company and want...</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>\\n$120,000 - $150,000 a year</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>Quantifind</td>\n",
       "      <td>Menlo Park, CA</td>\n",
       "      <td>\\nAt Quantifind, we look to integrate large amounts of data from diverse data sources (structured financial data or unstructured social data) to drive important...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>Capella Space</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>\\nCapella is looking for an enthusiastic remote sensing data scientist with expertise in radar signal processing, electro-optical data analysis, machine learning...</td>\n",
       "      <td>Remote Sensing Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>USC</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>\\nAn innovative data core provides sophisticated data and analytic support – including research programmers, a statistician, system administrator, and a data...</td>\n",
       "      <td>Elizabeth Garrett Chair in Health Policy, Economics, &amp; Law</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>Becton Dickinson &amp; Company</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>\\nCreate tools and processes to download data, parse it for relevant content, and store it in existing data management systems....</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>Fitbit</td>\n",
       "      <td>San Francisco, CA 94105 (Financial District area)</td>\n",
       "      <td>\\nPassion for data and data mining. Mine field data generated by Fitbit devices. Design, develop and build scripts to automate data processing....</td>\n",
       "      <td>Firmware Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>Sigmaways</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>\\nUnsupervised feature learning, streaming data analysis, temporal data analytics, multi-modal and heterogeneous data analysis....</td>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>Coupang</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>\\nThe experimentation platform team at Coupang is looking for a Principal Data Scientist with a solid background in experimentation methodologies....</td>\n",
       "      <td>Sr. Principal Data Scientist (Experimentation Platform)</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>The North Face</td>\n",
       "      <td>Alameda, CA</td>\n",
       "      <td>\\nInspire, manage and develop the team's data scientist. Manage agencies to help drive digital data innovation....</td>\n",
       "      <td>VF Corporation: Director, Digital Analytics</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>Galvanize</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>\\nJoin us in building the world's hub for education in data science and data engineering. Our Data Science Instructors train technical professionals with...</td>\n",
       "      <td>Lead Instructor, Principal Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>Quantifind</td>\n",
       "      <td>Menlo Park, CA</td>\n",
       "      <td>\\nAt Quantifind, we look to integrate large amounts of data from diverse data sources (structured financial data or unstructured social data) to drive important...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>Capella Space</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>\\nCapella is looking for an enthusiastic remote sensing data scientist with expertise in radar signal processing, electro-optical data analysis, machine learning...</td>\n",
       "      <td>Remote Sensing Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>USC</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>\\nAn innovative data core provides sophisticated data and analytic support – including research programmers, a statistician, system administrator, and a data...</td>\n",
       "      <td>Elizabeth Garrett Chair in Health Policy, Economics, &amp; Law</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>Becton Dickinson &amp; Company</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>\\nCreate tools and processes to download data, parse it for relevant content, and store it in existing data management systems....</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>Fitbit</td>\n",
       "      <td>San Francisco, CA 94105 (Financial District area)</td>\n",
       "      <td>\\nPassion for data and data mining. Mine field data generated by Fitbit devices. Design, develop and build scripts to automate data processing....</td>\n",
       "      <td>Firmware Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>Sigmaways</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>\\nUnsupervised feature learning, streaming data analysis, temporal data analytics, multi-modal and heterogeneous data analysis....</td>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>Coupang</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>\\nThe experimentation platform team at Coupang is looking for a Principal Data Scientist with a solid background in experimentation methodologies....</td>\n",
       "      <td>Sr. Principal Data Scientist (Experimentation Platform)</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>The North Face</td>\n",
       "      <td>Alameda, CA</td>\n",
       "      <td>\\nInspire, manage and develop the team's data scientist. Manage agencies to help drive digital data innovation....</td>\n",
       "      <td>VF Corporation: Director, Digital Analytics</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>Galvanize</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>\\nJoin us in building the world's hub for education in data science and data engineering. Our Data Science Instructors train technical professionals with...</td>\n",
       "      <td>Lead Instructor, Principal Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>Quantifind</td>\n",
       "      <td>Menlo Park, CA</td>\n",
       "      <td>\\nAt Quantifind, we look to integrate large amounts of data from diverse data sources (structured financial data or unstructured social data) to drive important...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Capella Space</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>\\nCapella is looking for an enthusiastic remote sensing data scientist with expertise in radar signal processing, electro-optical data analysis, machine learning...</td>\n",
       "      <td>Remote Sensing Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>USC</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>\\nAn innovative data core provides sophisticated data and analytic support – including research programmers, a statistician, system administrator, and a data...</td>\n",
       "      <td>Elizabeth Garrett Chair in Health Policy, Economics, &amp; Law</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>Becton Dickinson &amp; Company</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>\\nCreate tools and processes to download data, parse it for relevant content, and store it in existing data management systems....</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>Fitbit</td>\n",
       "      <td>San Francisco, CA 94105 (Financial District area)</td>\n",
       "      <td>\\nPassion for data and data mining. Mine field data generated by Fitbit devices. Design, develop and build scripts to automate data processing....</td>\n",
       "      <td>Firmware Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>Sigmaways</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>\\nUnsupervised feature learning, streaming data analysis, temporal data analytics, multi-modal and heterogeneous data analysis....</td>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>Coupang</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>\\nThe experimentation platform team at Coupang is looking for a Principal Data Scientist with a solid background in experimentation methodologies....</td>\n",
       "      <td>Sr. Principal Data Scientist (Experimentation Platform)</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>The North Face</td>\n",
       "      <td>Alameda, CA</td>\n",
       "      <td>\\nInspire, manage and develop the team's data scientist. Manage agencies to help drive digital data innovation....</td>\n",
       "      <td>VF Corporation: Director, Digital Analytics</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>Galvanize</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>\\nJoin us in building the world's hub for education in data science and data engineering. Our Data Science Instructors train technical professionals with...</td>\n",
       "      <td>Lead Instructor, Principal Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>Quantifind</td>\n",
       "      <td>Menlo Park, CA</td>\n",
       "      <td>\\nAt Quantifind, we look to integrate large amounts of data from diverse data sources (structured financial data or unstructured social data) to drive important...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>Capella Space</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>\\nCapella is looking for an enthusiastic remote sensing data scientist with expertise in radar signal processing, electro-optical data analysis, machine learning...</td>\n",
       "      <td>Remote Sensing Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>USC</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>\\nAn innovative data core provides sophisticated data and analytic support – including research programmers, a statistician, system administrator, and a data...</td>\n",
       "      <td>Elizabeth Garrett Chair in Health Policy, Economics, &amp; Law</td>\n",
       "      <td>None</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            comp_name  \\\n",
       "0                     CLARA analytics   \n",
       "1                          Shutterfly   \n",
       "2                        Lam Research   \n",
       "3                         GRAIL, Inc.   \n",
       "4                       Chatham Group   \n",
       "5                               Petco   \n",
       "6               Workbridge Associates   \n",
       "7                  Jobspring Partners   \n",
       "8                              Remind   \n",
       "9                            FullDeck   \n",
       "10                         Brainworks   \n",
       "11                             Atreca   \n",
       "12   The Honest Company (Career Page)   \n",
       "13                           Symantec   \n",
       "14                          NEURALINK   \n",
       "15                              Veeva   \n",
       "16                             SpaceX   \n",
       "17                        Mission Bio   \n",
       "18                          Accenture   \n",
       "19                            Twitter   \n",
       "20                        ZestFinance   \n",
       "21                          Xiar Tech   \n",
       "22                          Accenture   \n",
       "23                   General Electric   \n",
       "24              Infolob Solutions Inc   \n",
       "25                        Wells Fargo   \n",
       "26                              [24]7   \n",
       "27                         Activision   \n",
       "28                               Mode   \n",
       "29                 Jobspring Partners   \n",
       "..                                ...   \n",
       "870                        Quantifind   \n",
       "871                     Capella Space   \n",
       "872                               USC   \n",
       "873        Becton Dickinson & Company   \n",
       "874                            Fitbit   \n",
       "875                         Sigmaways   \n",
       "876                           Coupang   \n",
       "877                    The North Face   \n",
       "878                         Galvanize   \n",
       "879                        Quantifind   \n",
       "880                     Capella Space   \n",
       "881                               USC   \n",
       "882        Becton Dickinson & Company   \n",
       "883                            Fitbit   \n",
       "884                         Sigmaways   \n",
       "885                           Coupang   \n",
       "886                    The North Face   \n",
       "887                         Galvanize   \n",
       "888                        Quantifind   \n",
       "889                     Capella Space   \n",
       "890                               USC   \n",
       "891        Becton Dickinson & Company   \n",
       "892                            Fitbit   \n",
       "893                         Sigmaways   \n",
       "894                           Coupang   \n",
       "895                    The North Face   \n",
       "896                         Galvanize   \n",
       "897                        Quantifind   \n",
       "898                     Capella Space   \n",
       "899                               USC   \n",
       "\n",
       "                                          job_location  \\\n",
       "0                                      Santa Clara, CA   \n",
       "1                                     Redwood City, CA   \n",
       "2                   Fremont, CA 94538 (Irvington area)   \n",
       "3                                       Menlo Park, CA   \n",
       "4    San Francisco, CA 94104 (Financial District area)   \n",
       "5                                        San Diego, CA   \n",
       "6                   San Jose, CA 95113 (Downtown area)   \n",
       "7                                        Palo Alto, CA   \n",
       "8                                    San Francisco, CA   \n",
       "9                                      Los Angeles, CA   \n",
       "10                                         Oakland, CA   \n",
       "11                              Redwood City, CA 94063   \n",
       "12                                     Los Angeles, CA   \n",
       "13                                   Mountain View, CA   \n",
       "14                                   San Francisco, CA   \n",
       "15                                      Pleasanton, CA   \n",
       "16                                       Hawthorne, CA   \n",
       "17                                   San Francisco, CA   \n",
       "18                                       San Diego, CA   \n",
       "19      San Francisco, CA 94103 (South Of Market area)   \n",
       "20                                     Los Angeles, CA   \n",
       "21           Palo Alto, CA 94301 (Professorville area)   \n",
       "22                                       San Diego, CA   \n",
       "23             San Francisco, CA 94102 (Downtown area)   \n",
       "24        San Francisco, CA 94112 (Outer Mission area)   \n",
       "25                                         Concord, CA   \n",
       "26                                        San Jose, CA   \n",
       "27                                     Foster City, CA   \n",
       "28                                   San Francisco, CA   \n",
       "29                  San Jose, CA 95113 (Downtown area)   \n",
       "..                                                 ...   \n",
       "870                                     Menlo Park, CA   \n",
       "871                                      Palo Alto, CA   \n",
       "872                                    Los Angeles, CA   \n",
       "873                                      San Diego, CA   \n",
       "874  San Francisco, CA 94105 (Financial District area)   \n",
       "875                                      Palo Alto, CA   \n",
       "876                                  Mountain View, CA   \n",
       "877                                        Alameda, CA   \n",
       "878                                  San Francisco, CA   \n",
       "879                                     Menlo Park, CA   \n",
       "880                                      Palo Alto, CA   \n",
       "881                                    Los Angeles, CA   \n",
       "882                                      San Diego, CA   \n",
       "883  San Francisco, CA 94105 (Financial District area)   \n",
       "884                                      Palo Alto, CA   \n",
       "885                                  Mountain View, CA   \n",
       "886                                        Alameda, CA   \n",
       "887                                  San Francisco, CA   \n",
       "888                                     Menlo Park, CA   \n",
       "889                                      Palo Alto, CA   \n",
       "890                                    Los Angeles, CA   \n",
       "891                                      San Diego, CA   \n",
       "892  San Francisco, CA 94105 (Financial District area)   \n",
       "893                                      Palo Alto, CA   \n",
       "894                                  Mountain View, CA   \n",
       "895                                        Alameda, CA   \n",
       "896                                  San Francisco, CA   \n",
       "897                                     Menlo Park, CA   \n",
       "898                                      Palo Alto, CA   \n",
       "899                                    Los Angeles, CA   \n",
       "\n",
       "                                                                                                                                                               job_summary  \\\n",
       "0            \\nThe Data Scientist role involves working on all stages of the data science pipeline, from acquiring and assessing data, selecting appropriate models and...   \n",
       "1        \\nThe Data Scientist will be responsible for designing and directing experiments and observational studies to optimize our customer acquisition and engagement...   \n",
       "2                                          \\nDefine data structures, evaluate data quality, perform appropriate data analyses using software such as Python and MATLAB....   \n",
       "3      \\nParticipate in data quality review activities and efforts to resolve data quality issues. Develop and manage interactive data visualization and analytic tools...   \n",
       "4                                             \\nDo you like data? Experience in data analysis, gaming, mobile applications, consulting, or business/financial analysis....   \n",
       "5                     \\nThis role will supervise the assistant merchant managers and work very closely with the customer data scientist and manager business analytics....   \n",
       "6     \\nA well-established retail company located in Silicon Valley is looking for a contract Senior Data Scientist to take on a role providing modeling, analysis, and...   \n",
       "7                                       \\nA Series C Healthcare Startup Located in Palo Alto is on the seeking for a bold Mid-Level Data Scientist to join to the team....   \n",
       "8              \\nAnalyze data to identify trends and opportunities, surface actionable insights, and help teams set goals, forecasts and prioritization of initiatives....   \n",
       "9    \\n2+ years of experience in data mining and/or data science. A flourishing digital media agency with high profile entertainment clients, has an immediate need for...   \n",
       "10   \\nOur client, a fast-growing, well-funded, ecommerce start-up is looking for a Data Scientist . You will assist in building a data driven culture by exploring the...   \n",
       "11      \\nWe are looking for a Data Scientist who will help us use the information hidden in vast amounts of data to make smarter research decisions and discover novel...   \n",
       "12    \\nWe're currently looking to add another Data Scientist to our fantastic Data team. As a Data Scientist, you'll have the opportunity to inform business decisions...   \n",
       "13                                            \\nData acquisition will require navigation of Hadoop, Spark, databases (SQL), 3rd party data sources and text processing....   \n",
       "14                      \\nExperience with biological data. Experience with time series data. Develop machine-learning techniques for decoding neural data in real time....   \n",
       "15          \\nCombine your love and knowledge of quantitative data analysis across large data sets with solid presentation skills Use statistical methods to derive new...   \n",
       "16         \\nPerform exploratory data analysis, extract data from various sources, clean and aggregate data. The Data Science team is a new team in the Enterprise Data...   \n",
       "17         \\nWe are seeking a highly-motivated Data Scientist I/II to provide analytical support of sequencing data from our proprietary single-cell genomics platform....   \n",
       "18                                            \\nData Scientist Specialist. Core Data Scientist team. Scientist Specialist manages, architects and analyzes big data in....   \n",
       "19         \\nYou will build Twitter’s next-generation Tailored Audience Targeting platform, working closely with product managers, data scientist, and machine learning...   \n",
       "20                             \\nRecruit, motivate, and develop the best data scientist talent in the world. Experience developing real-time production data pipelines....   \n",
       "21         \\nData ScientistPalo Alto, CA6+monthsPlease look for local consultants only.We are looking for a Data Scientist with a large client – experience required is...   \n",
       "22               \\nThe Data Scientist. Data Scientist Associate Principal. Statistical and machine learning models, data mining, unstructured data. Data Scientists in....   \n",
       "23        \\nYou will be working with world class data scientist, engineers, designers, and domain experts to support state-of-the-art AI and machine learning solutions...   \n",
       "24           \\nProvided by Dice Data Scientist, Spark, Scala, Python, Data Scientist. Senior Data ScientistLocation:. Looking for a strong Data Scientist with hands on...   \n",
       "25         \\nReporting, analytics, Data modeling, Data Structures and Algorithms. This person will be a key contributor to the Artificial Intelligence/Machine Learning...   \n",
       "26                                      \\nAnalyze application data. The Data Scientist will be responsible for continually improving 24/7’s premier voice applications....   \n",
       "27         \\nAnd data transformations. Strong data visualization and. Scientist with strong analytical skills. Data visualizations and integrating with analytics APIs....   \n",
       "28     \\nComfort with SQL and web-based technologies—You don't need be an engineer or data scientist, but you should know how to write a query and comfortable learning...   \n",
       "29     \\nSome work with Big Data technologies (Spark). 2 + years of experience in Data Science. At the moment, they are looking to further build their company and want...   \n",
       "..                                                                                                                                                                     ...   \n",
       "870    \\nAt Quantifind, we look to integrate large amounts of data from diverse data sources (structured financial data or unstructured social data) to drive important...   \n",
       "871   \\nCapella is looking for an enthusiastic remote sensing data scientist with expertise in radar signal processing, electro-optical data analysis, machine learning...   \n",
       "872       \\nAn innovative data core provides sophisticated data and analytic support – including research programmers, a statistician, system administrator, and a data...   \n",
       "873                                     \\nCreate tools and processes to download data, parse it for relevant content, and store it in existing data management systems....   \n",
       "874                     \\nPassion for data and data mining. Mine field data generated by Fitbit devices. Design, develop and build scripts to automate data processing....   \n",
       "875                                     \\nUnsupervised feature learning, streaming data analysis, temporal data analytics, multi-modal and heterogeneous data analysis....   \n",
       "876                  \\nThe experimentation platform team at Coupang is looking for a Principal Data Scientist with a solid background in experimentation methodologies....   \n",
       "877                                                     \\nInspire, manage and develop the team's data scientist. Manage agencies to help drive digital data innovation....   \n",
       "878           \\nJoin us in building the world's hub for education in data science and data engineering. Our Data Science Instructors train technical professionals with...   \n",
       "879    \\nAt Quantifind, we look to integrate large amounts of data from diverse data sources (structured financial data or unstructured social data) to drive important...   \n",
       "880   \\nCapella is looking for an enthusiastic remote sensing data scientist with expertise in radar signal processing, electro-optical data analysis, machine learning...   \n",
       "881       \\nAn innovative data core provides sophisticated data and analytic support – including research programmers, a statistician, system administrator, and a data...   \n",
       "882                                     \\nCreate tools and processes to download data, parse it for relevant content, and store it in existing data management systems....   \n",
       "883                     \\nPassion for data and data mining. Mine field data generated by Fitbit devices. Design, develop and build scripts to automate data processing....   \n",
       "884                                     \\nUnsupervised feature learning, streaming data analysis, temporal data analytics, multi-modal and heterogeneous data analysis....   \n",
       "885                  \\nThe experimentation platform team at Coupang is looking for a Principal Data Scientist with a solid background in experimentation methodologies....   \n",
       "886                                                     \\nInspire, manage and develop the team's data scientist. Manage agencies to help drive digital data innovation....   \n",
       "887           \\nJoin us in building the world's hub for education in data science and data engineering. Our Data Science Instructors train technical professionals with...   \n",
       "888    \\nAt Quantifind, we look to integrate large amounts of data from diverse data sources (structured financial data or unstructured social data) to drive important...   \n",
       "889   \\nCapella is looking for an enthusiastic remote sensing data scientist with expertise in radar signal processing, electro-optical data analysis, machine learning...   \n",
       "890       \\nAn innovative data core provides sophisticated data and analytic support – including research programmers, a statistician, system administrator, and a data...   \n",
       "891                                     \\nCreate tools and processes to download data, parse it for relevant content, and store it in existing data management systems....   \n",
       "892                     \\nPassion for data and data mining. Mine field data generated by Fitbit devices. Design, develop and build scripts to automate data processing....   \n",
       "893                                     \\nUnsupervised feature learning, streaming data analysis, temporal data analytics, multi-modal and heterogeneous data analysis....   \n",
       "894                  \\nThe experimentation platform team at Coupang is looking for a Principal Data Scientist with a solid background in experimentation methodologies....   \n",
       "895                                                     \\nInspire, manage and develop the team's data scientist. Manage agencies to help drive digital data innovation....   \n",
       "896           \\nJoin us in building the world's hub for education in data science and data engineering. Our Data Science Instructors train technical professionals with...   \n",
       "897    \\nAt Quantifind, we look to integrate large amounts of data from diverse data sources (structured financial data or unstructured social data) to drive important...   \n",
       "898   \\nCapella is looking for an enthusiastic remote sensing data scientist with expertise in radar signal processing, electro-optical data analysis, machine learning...   \n",
       "899       \\nAn innovative data core provides sophisticated data and analytic support – including research programmers, a statistician, system administrator, and a data...   \n",
       "\n",
       "                                                      job_title  \\\n",
       "0                                                Data Scientist   \n",
       "1                                                Data Scientist   \n",
       "2                                              Data Scientist 4   \n",
       "3                          Senior Staff Clinical Data Scientist   \n",
       "4                                         Senior Data Scientist   \n",
       "5                                              Services Manager   \n",
       "6                              Senior Data Scientist (Contract)   \n",
       "7                                      Mid-level Data Scientist   \n",
       "8                                                Data Scientist   \n",
       "9                                                Data Scientist   \n",
       "10                                               Data Scientist   \n",
       "11                                               Data Scientist   \n",
       "12                                               Data Scientist   \n",
       "13                            Research Engineer/ Data Scientist   \n",
       "14                                               Data Scientist   \n",
       "15                               Data Scientist - Deep Learning   \n",
       "16                                           Sr. Data Scientist   \n",
       "17                                          Data Scientist I/II   \n",
       "18                                    Data Scientist Specialist   \n",
       "19                                   Software Engineer, Backend   \n",
       "20                                       Director, Data Science   \n",
       "21                                               Data Scientist   \n",
       "22                           Data Scientist Associate Principal   \n",
       "23                                Sr Software Engineer - DevOps   \n",
       "24                               Senior Data Scientist (Remote)   \n",
       "25                                           Analytic Manager 4   \n",
       "26                                               Data Scientist   \n",
       "27                             Data Scientist - Foster City, CA   \n",
       "28                                     Customer Support Analyst   \n",
       "29                                        Junior Data Scientist   \n",
       "..                                                          ...   \n",
       "870                                       Senior Data Scientist   \n",
       "871                                    Remote Sensing Scientist   \n",
       "872  Elizabeth Garrett Chair in Health Policy, Economics, & Law   \n",
       "873                                              Data Scientist   \n",
       "874                                     Firmware Data Scientist   \n",
       "875                                          Sr. Data Scientist   \n",
       "876     Sr. Principal Data Scientist (Experimentation Platform)   \n",
       "877                 VF Corporation: Director, Digital Analytics   \n",
       "878                   Lead Instructor, Principal Data Scientist   \n",
       "879                                       Senior Data Scientist   \n",
       "880                                    Remote Sensing Scientist   \n",
       "881  Elizabeth Garrett Chair in Health Policy, Economics, & Law   \n",
       "882                                              Data Scientist   \n",
       "883                                     Firmware Data Scientist   \n",
       "884                                          Sr. Data Scientist   \n",
       "885     Sr. Principal Data Scientist (Experimentation Platform)   \n",
       "886                 VF Corporation: Director, Digital Analytics   \n",
       "887                   Lead Instructor, Principal Data Scientist   \n",
       "888                                       Senior Data Scientist   \n",
       "889                                    Remote Sensing Scientist   \n",
       "890  Elizabeth Garrett Chair in Health Policy, Economics, & Law   \n",
       "891                                              Data Scientist   \n",
       "892                                     Firmware Data Scientist   \n",
       "893                                          Sr. Data Scientist   \n",
       "894     Sr. Principal Data Scientist (Experimentation Platform)   \n",
       "895                 VF Corporation: Director, Digital Analytics   \n",
       "896                   Lead Instructor, Principal Data Scientist   \n",
       "897                                       Senior Data Scientist   \n",
       "898                                    Remote Sensing Scientist   \n",
       "899  Elizabeth Garrett Chair in Health Policy, Economics, & Law   \n",
       "\n",
       "                listed_job_salary  salary_estimated  \n",
       "0                            None           60000.0  \n",
       "1                            None           60000.0  \n",
       "2                            None           60000.0  \n",
       "3                            None           60000.0  \n",
       "4                \\n$70,000 a year           60000.0  \n",
       "5                            None           60000.0  \n",
       "6                            None           60000.0  \n",
       "7    \\n$130,000 - $165,000 a year           60000.0  \n",
       "8                            None           60000.0  \n",
       "9                            None           60000.0  \n",
       "10                           None           60000.0  \n",
       "11                           None           60000.0  \n",
       "12                           None           60000.0  \n",
       "13                           None           60000.0  \n",
       "14                           None           60000.0  \n",
       "15                           None           60000.0  \n",
       "16                           None           60000.0  \n",
       "17                           None           60000.0  \n",
       "18                           None           60000.0  \n",
       "19                           None           60000.0  \n",
       "20                           None           60000.0  \n",
       "21                           None           60000.0  \n",
       "22                           None           60000.0  \n",
       "23                           None           60000.0  \n",
       "24                           None           60000.0  \n",
       "25                           None           60000.0  \n",
       "26                           None           60000.0  \n",
       "27                           None           60000.0  \n",
       "28                           None           60000.0  \n",
       "29   \\n$120,000 - $150,000 a year           60000.0  \n",
       "..                            ...               ...  \n",
       "870                          None           60000.0  \n",
       "871                          None           60000.0  \n",
       "872                          None           60000.0  \n",
       "873                          None           60000.0  \n",
       "874                          None           60000.0  \n",
       "875                          None           60000.0  \n",
       "876                          None           60000.0  \n",
       "877                          None           60000.0  \n",
       "878                          None           60000.0  \n",
       "879                          None           60000.0  \n",
       "880                          None           60000.0  \n",
       "881                          None           60000.0  \n",
       "882                          None           60000.0  \n",
       "883                          None           60000.0  \n",
       "884                          None           60000.0  \n",
       "885                          None           60000.0  \n",
       "886                          None           60000.0  \n",
       "887                          None           60000.0  \n",
       "888                          None           60000.0  \n",
       "889                          None           60000.0  \n",
       "890                          None           60000.0  \n",
       "891                          None           60000.0  \n",
       "892                          None           60000.0  \n",
       "893                          None           60000.0  \n",
       "894                          None           60000.0  \n",
       "895                          None           60000.0  \n",
       "896                          None           60000.0  \n",
       "897                          None           60000.0  \n",
       "898                          None           60000.0  \n",
       "899                          None           60000.0  \n",
       "\n",
       "[900 rows x 6 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = scrape(df2, url_ca_exact_60, 60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = scrape(df2, url_ca_exact_80, 80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = scrape(df2, url_ca_exact_95, 95000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = scrape(df2, url_ca_exact_110, 110000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.replace('\\n','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the result to CSV\n",
    "df2.to_csv('../indeed-results-exact-ds.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:800px;background:#ffff00;border:1px solid black;text-align:left;padding:8px;\">\n",
    "\n",
    "Same initial cleaning, duplicate dropping, and location fixing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_exact = pd.read_csv('../indeed-results-exact-ds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_exact.drop([\"Unnamed: 0\", \"listed_job_salary\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_exact.drop_duplicates(subset='job_summary', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_estimated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLARA analytics</td>\n",
       "      <td>Santa Clara, CA</td>\n",
       "      <td>The Data Scientist role involves working on al...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shutterfly</td>\n",
       "      <td>Redwood City, CA</td>\n",
       "      <td>The Data Scientist will be responsible for des...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lam Research</td>\n",
       "      <td>Fremont, CA 94538 (Irvington area)</td>\n",
       "      <td>Define data structures, evaluate data quality,...</td>\n",
       "      <td>Data Scientist 4</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRAIL, Inc.</td>\n",
       "      <td>Menlo Park, CA</td>\n",
       "      <td>Participate in data quality review activities ...</td>\n",
       "      <td>Senior Staff Clinical Data Scientist</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chatham Group</td>\n",
       "      <td>San Francisco, CA 94104 (Financial District area)</td>\n",
       "      <td>Do you like data? Experience in data analysis,...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         comp_name                                       job_location  \\\n",
       "0  CLARA analytics                                    Santa Clara, CA   \n",
       "1       Shutterfly                                   Redwood City, CA   \n",
       "2     Lam Research                 Fremont, CA 94538 (Irvington area)   \n",
       "3      GRAIL, Inc.                                     Menlo Park, CA   \n",
       "4    Chatham Group  San Francisco, CA 94104 (Financial District area)   \n",
       "\n",
       "                                         job_summary  \\\n",
       "0  The Data Scientist role involves working on al...   \n",
       "1  The Data Scientist will be responsible for des...   \n",
       "2  Define data structures, evaluate data quality,...   \n",
       "3  Participate in data quality review activities ...   \n",
       "4  Do you like data? Experience in data analysis,...   \n",
       "\n",
       "                              job_title  salary_estimated  \n",
       "0                        Data Scientist           60000.0  \n",
       "1                        Data Scientist           60000.0  \n",
       "2                      Data Scientist 4           60000.0  \n",
       "3  Senior Staff Clinical Data Scientist           60000.0  \n",
       "4                 Senior Data Scientist           60000.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exact.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(851, 5)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exact.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Changed all the job titles to lower case so that our search is not case-sensitive\n",
    "df_exact[\"job_title\"] = df_exact.job_title.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_estimated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLARA analytics</td>\n",
       "      <td>Santa Clara, CA</td>\n",
       "      <td>The Data Scientist role involves working on al...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shutterfly</td>\n",
       "      <td>Redwood City, CA</td>\n",
       "      <td>The Data Scientist will be responsible for des...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lam Research</td>\n",
       "      <td>Fremont, CA 94538 (Irvington area)</td>\n",
       "      <td>Define data structures, evaluate data quality,...</td>\n",
       "      <td>data scientist 4</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRAIL, Inc.</td>\n",
       "      <td>Menlo Park, CA</td>\n",
       "      <td>Participate in data quality review activities ...</td>\n",
       "      <td>senior staff clinical data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chatham Group</td>\n",
       "      <td>San Francisco, CA 94104 (Financial District area)</td>\n",
       "      <td>Do you like data? Experience in data analysis,...</td>\n",
       "      <td>senior data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         comp_name                                       job_location  \\\n",
       "0  CLARA analytics                                    Santa Clara, CA   \n",
       "1       Shutterfly                                   Redwood City, CA   \n",
       "2     Lam Research                 Fremont, CA 94538 (Irvington area)   \n",
       "3      GRAIL, Inc.                                     Menlo Park, CA   \n",
       "4    Chatham Group  San Francisco, CA 94104 (Financial District area)   \n",
       "\n",
       "                                         job_summary  \\\n",
       "0  The Data Scientist role involves working on al...   \n",
       "1  The Data Scientist will be responsible for des...   \n",
       "2  Define data structures, evaluate data quality,...   \n",
       "3  Participate in data quality review activities ...   \n",
       "4  Do you like data? Experience in data analysis,...   \n",
       "\n",
       "                              job_title  salary_estimated  \n",
       "0                        data scientist           60000.0  \n",
       "1                        data scientist           60000.0  \n",
       "2                      data scientist 4           60000.0  \n",
       "3  senior staff clinical data scientist           60000.0  \n",
       "4                 senior data scientist           60000.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exact.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_exact.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:800px;background:#ffff00;border:1px solid black;text-align:left;padding:8px;\">\n",
    "\n",
    "We only considered data with any mention of \"Data Scientist\". We excluded any roles that only mention data scientist in the job summary, or if the title was something along the lines of \"data analyst\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jobs = []\n",
    "\n",
    "for a in range(len(df_exact[\"job_title\"])) :\n",
    "    if \"data scientist\" in df_exact[\"job_title\"][a] :\n",
    "        jobs.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ds = df_exact.iloc[jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_estimated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLARA analytics</td>\n",
       "      <td>Santa Clara, CA</td>\n",
       "      <td>The Data Scientist role involves working on al...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shutterfly</td>\n",
       "      <td>Redwood City, CA</td>\n",
       "      <td>The Data Scientist will be responsible for des...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lam Research</td>\n",
       "      <td>Fremont, CA 94538 (Irvington area)</td>\n",
       "      <td>Define data structures, evaluate data quality,...</td>\n",
       "      <td>data scientist 4</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRAIL, Inc.</td>\n",
       "      <td>Menlo Park, CA</td>\n",
       "      <td>Participate in data quality review activities ...</td>\n",
       "      <td>senior staff clinical data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chatham Group</td>\n",
       "      <td>San Francisco, CA 94104 (Financial District area)</td>\n",
       "      <td>Do you like data? Experience in data analysis,...</td>\n",
       "      <td>senior data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         comp_name                                       job_location  \\\n",
       "0  CLARA analytics                                    Santa Clara, CA   \n",
       "1       Shutterfly                                   Redwood City, CA   \n",
       "2     Lam Research                 Fremont, CA 94538 (Irvington area)   \n",
       "3      GRAIL, Inc.                                     Menlo Park, CA   \n",
       "4    Chatham Group  San Francisco, CA 94104 (Financial District area)   \n",
       "\n",
       "                                         job_summary  \\\n",
       "0  The Data Scientist role involves working on al...   \n",
       "1  The Data Scientist will be responsible for des...   \n",
       "2  Define data structures, evaluate data quality,...   \n",
       "3  Participate in data quality review activities ...   \n",
       "4  Do you like data? Experience in data analysis,...   \n",
       "\n",
       "                              job_title  salary_estimated  \n",
       "0                        data scientist           60000.0  \n",
       "1                        data scientist           60000.0  \n",
       "2                      data scientist 4           60000.0  \n",
       "3  senior staff clinical data scientist           60000.0  \n",
       "4                 senior data scientist           60000.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(691, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:800px;background:#ffff00;border:1px solid black;text-align:left;padding:8px;\">\n",
    "\n",
    "We use specific terms to isolate which positions are considered \"senior\" positions. Then, we assign the rows a value of \"Senior\" or \"Not Senior\" using 0 and 1 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searchfor = ['senior', 'lead', 'sr', 'principal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GuangYi/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "tf_vector = df_ds.job_title.str.contains('|'.join(searchfor))\n",
    "\n",
    "senior_not_senior = [1 if a == True else 0 for a in tf_vector]\n",
    "df_ds[\"senior_not_senior\"] = senior_not_senior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_estimated</th>\n",
       "      <th>senior_not_senior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLARA analytics</td>\n",
       "      <td>Santa Clara, CA</td>\n",
       "      <td>The Data Scientist role involves working on al...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shutterfly</td>\n",
       "      <td>Redwood City, CA</td>\n",
       "      <td>The Data Scientist will be responsible for des...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lam Research</td>\n",
       "      <td>Fremont, CA 94538 (Irvington area)</td>\n",
       "      <td>Define data structures, evaluate data quality,...</td>\n",
       "      <td>data scientist 4</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRAIL, Inc.</td>\n",
       "      <td>Menlo Park, CA</td>\n",
       "      <td>Participate in data quality review activities ...</td>\n",
       "      <td>senior staff clinical data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chatham Group</td>\n",
       "      <td>San Francisco, CA 94104 (Financial District area)</td>\n",
       "      <td>Do you like data? Experience in data analysis,...</td>\n",
       "      <td>senior data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         comp_name                                       job_location  \\\n",
       "0  CLARA analytics                                    Santa Clara, CA   \n",
       "1       Shutterfly                                   Redwood City, CA   \n",
       "2     Lam Research                 Fremont, CA 94538 (Irvington area)   \n",
       "3      GRAIL, Inc.                                     Menlo Park, CA   \n",
       "4    Chatham Group  San Francisco, CA 94104 (Financial District area)   \n",
       "\n",
       "                                         job_summary  \\\n",
       "0  The Data Scientist role involves working on al...   \n",
       "1  The Data Scientist will be responsible for des...   \n",
       "2  Define data structures, evaluate data quality,...   \n",
       "3  Participate in data quality review activities ...   \n",
       "4  Do you like data? Experience in data analysis,...   \n",
       "\n",
       "                              job_title  salary_estimated  senior_not_senior  \n",
       "0                        data scientist           60000.0                  0  \n",
       "1                        data scientist           60000.0                  0  \n",
       "2                      data scientist 4           60000.0                  0  \n",
       "3  senior staff clinical data scientist           60000.0                  1  \n",
       "4                 senior data scientist           60000.0                  1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(691, 6)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    413\n",
       "1    278\n",
       "Name: senior_not_senior, dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pretty well balanced\n",
    "df_ds[\"senior_not_senior\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GuangYi/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/GuangYi/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comp_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_estimated</th>\n",
       "      <th>senior_not_senior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLARA analytics</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>The Data Scientist role involves working on al...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shutterfly</td>\n",
       "      <td>Redwood City</td>\n",
       "      <td>The Data Scientist will be responsible for des...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lam Research</td>\n",
       "      <td>Fremont</td>\n",
       "      <td>Define data structures, evaluate data quality,...</td>\n",
       "      <td>data scientist 4</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRAIL, Inc.</td>\n",
       "      <td>Menlo Park</td>\n",
       "      <td>Participate in data quality review activities ...</td>\n",
       "      <td>senior staff clinical data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chatham Group</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Do you like data? Experience in data analysis,...</td>\n",
       "      <td>senior data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>A well-established retail company located in S...</td>\n",
       "      <td>senior data scientist (contract)</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>A Series C Healthcare Startup Located in Palo ...</td>\n",
       "      <td>mid-level data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Remind</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Analyze data to identify trends and opportunit...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FullDeck</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>2+ years of experience in data mining and/or d...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Brainworks</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>Our client, a fast-growing, well-funded, ecomm...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Atreca</td>\n",
       "      <td>Redwood City</td>\n",
       "      <td>We are looking for a Data Scientist who will h...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Honest Company (Career Page)</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>We're currently looking to add another Data Sc...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Symantec</td>\n",
       "      <td>Mountain View</td>\n",
       "      <td>Data acquisition will require navigation of Ha...</td>\n",
       "      <td>research engineer/ data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NEURALINK</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Experience with biological data. Experience wi...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Veeva</td>\n",
       "      <td>Pleasanton</td>\n",
       "      <td>Combine your love and knowledge of quantitativ...</td>\n",
       "      <td>data scientist - deep learning</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SpaceX</td>\n",
       "      <td>Hawthorne</td>\n",
       "      <td>Perform exploratory data analysis, extract dat...</td>\n",
       "      <td>sr. data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Mission Bio</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>We are seeking a highly-motivated Data Scienti...</td>\n",
       "      <td>data scientist i/ii</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>Data Scientist Specialist. Core Data Scientist...</td>\n",
       "      <td>data scientist specialist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Xiar Tech</td>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Data ScientistPalo Alto, CA6+monthsPlease look...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>The Data Scientist. Data Scientist Associate P...</td>\n",
       "      <td>data scientist associate principal</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Infolob Solutions Inc</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Provided by Dice Data Scientist, Spark, Scala,...</td>\n",
       "      <td>senior data scientist (remote)</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[24]7</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>Analyze application data. The Data Scientist w...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Activision</td>\n",
       "      <td>Foster City</td>\n",
       "      <td>And data transformations. Strong data visualiz...</td>\n",
       "      <td>data scientist - foster city, ca</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>Some work with Big Data technologies (Spark). ...</td>\n",
       "      <td>junior data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Esurance</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Extensive experience in data management and da...</td>\n",
       "      <td>sr data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Databricks</td>\n",
       "      <td>San Francisco Bay Area</td>\n",
       "      <td>Design and lead data scientists to build data ...</td>\n",
       "      <td>lead data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Metabyte</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>Functionally leading a cohesive data strategy ...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>Experience with big data tech such as Spark or...</td>\n",
       "      <td>junior data scientist (security space)</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Integrated Management Resources, LLC</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Enterprise Data and Client Insight office work...</td>\n",
       "      <td>data scientist-san francisco</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Elti Solutions</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Data Analytics, Hadoop, Cloud Computing, Data ...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>Acxiom</td>\n",
       "      <td>Redwood City</td>\n",
       "      <td>We are seeking an experienced Data Scientist w...</td>\n",
       "      <td>acxiom labs - data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>Blizzard Entertainment</td>\n",
       "      <td>Irvine</td>\n",
       "      <td>Experience with data visualization tools like ...</td>\n",
       "      <td>sr. data scientist, global insights - nlp</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>Akamai</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>If you have a deep passion for data and securi...</td>\n",
       "      <td>principal lead data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>The Aerospace Corporation</td>\n",
       "      <td>El Segundo</td>\n",
       "      <td>Experience in data science projects. Experienc...</td>\n",
       "      <td>signal processing data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>Kennedy Unlimited Inc, Professional Staffing</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Responsibilities of the Data Scientist Data Mo...</td>\n",
       "      <td>data scientist data modeling (machine learning...</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>Plantronics</td>\n",
       "      <td>Santa Cruz</td>\n",
       "      <td>Provide subject matter expertise in statistica...</td>\n",
       "      <td>senior r&amp;d data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>Paypal</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>Have a passion for working on big data and pro...</td>\n",
       "      <td>lead data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Experience with geospatial data and/or data vi...</td>\n",
       "      <td>data scientist (analytics)</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>Salesforce</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>You’re intensely curious about data and highly...</td>\n",
       "      <td>lead / principal data scientist - security ana...</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>Payette Group</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Data Scientist Machine Learning. Professional ...</td>\n",
       "      <td>data scientist - machine learning</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>Pfizer Inc.</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Associate Director- Clinical Data Scientist. T...</td>\n",
       "      <td>associate director, clinical data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>Glocomms</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>A leading mobile audience intelligence company...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>Clicktripz</td>\n",
       "      <td>Manhattan Beach</td>\n",
       "      <td>Clicktripz is looking for a skilled Data Scien...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>Uber</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Large scale data management:. About the roleAs...</td>\n",
       "      <td>data scientist, ai labs</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>art.com</td>\n",
       "      <td>Emeryville</td>\n",
       "      <td>Art.com seeks a full-time Data Scientist to tr...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>The Climate Corporation</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>We work with weather data, agricultural statis...</td>\n",
       "      <td>deep learning data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>GRAIL, Inc.</td>\n",
       "      <td>Menlo Park</td>\n",
       "      <td>Participate in data quality review activities ...</td>\n",
       "      <td>clinical data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>Huawei</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>Automate data collection, pre-processing and/o...</td>\n",
       "      <td>distinguished data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>Honey</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Proficient at programming in Python and famili...</td>\n",
       "      <td>senior data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>Spokeo</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>Spokeo is seeking a Senior Data Scientist to j...</td>\n",
       "      <td>senior data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>Earnest</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Earnest is driven by data. We practice full st...</td>\n",
       "      <td>sr. data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>LogMeIn, Inc.</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>LEAD DATA SCIENTIST, MARKETING ANALYTICS. Comf...</td>\n",
       "      <td>lead data scientist, marketing analytics</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>Data Scientist to join our growing Infosight D...</td>\n",
       "      <td>sr. data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>GoPro Careers Page</td>\n",
       "      <td>San Mateo</td>\n",
       "      <td>Experience working with large data sets. To re...</td>\n",
       "      <td>sr. data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>smartdrive</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>Develop algorithms that collect continuous dat...</td>\n",
       "      <td>principal data scientist, classification and f...</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>Grand Rounds</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Data scale ranges from small data sets that fi...</td>\n",
       "      <td>senior data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>eBay Inc.</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>We use state-of-the-art big data infrastructur...</td>\n",
       "      <td>data scientist / applied researcher</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>Trusted Insight, Inc.</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Generate new models to classify, homogenize an...</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>YuMe</td>\n",
       "      <td>Redwood City</td>\n",
       "      <td>Join YuMe as a data scientist to be part of ou...</td>\n",
       "      <td>sr. data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>DataRobot</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>As a Customer Facing Data Scientist, you will ...</td>\n",
       "      <td>partners - customer facing data scientist</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>691 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comp_name            job_location  \\\n",
       "0                                 CLARA analytics             Santa Clara   \n",
       "1                                      Shutterfly            Redwood City   \n",
       "2                                    Lam Research                 Fremont   \n",
       "3                                     GRAIL, Inc.              Menlo Park   \n",
       "4                                   Chatham Group           San Francisco   \n",
       "5                           Workbridge Associates                San Jose   \n",
       "6                              Jobspring Partners               Palo Alto   \n",
       "7                                          Remind           San Francisco   \n",
       "8                                        FullDeck             Los Angeles   \n",
       "9                                      Brainworks                 Oakland   \n",
       "10                                         Atreca            Redwood City   \n",
       "11               The Honest Company (Career Page)             Los Angeles   \n",
       "12                                       Symantec           Mountain View   \n",
       "13                                      NEURALINK           San Francisco   \n",
       "14                                          Veeva              Pleasanton   \n",
       "15                                         SpaceX               Hawthorne   \n",
       "16                                    Mission Bio           San Francisco   \n",
       "17                                      Accenture               San Diego   \n",
       "18                                      Xiar Tech               Palo Alto   \n",
       "19                                      Accenture               San Diego   \n",
       "20                          Infolob Solutions Inc           San Francisco   \n",
       "21                                          [24]7                San Jose   \n",
       "22                                     Activision             Foster City   \n",
       "23                             Jobspring Partners                San Jose   \n",
       "24                                       Esurance           San Francisco   \n",
       "25                                     Databricks  San Francisco Bay Area   \n",
       "26                                       Metabyte                San Jose   \n",
       "27                             Jobspring Partners                San Jose   \n",
       "28           Integrated Management Resources, LLC           San Francisco   \n",
       "29                                 Elti Solutions           San Francisco   \n",
       "..                                            ...                     ...   \n",
       "661                                        Acxiom            Redwood City   \n",
       "662                        Blizzard Entertainment                  Irvine   \n",
       "663                                        Akamai             Santa Clara   \n",
       "664                     The Aerospace Corporation              El Segundo   \n",
       "665  Kennedy Unlimited Inc, Professional Staffing           San Francisco   \n",
       "666                                   Plantronics              Santa Cruz   \n",
       "667                                        Paypal                San Jose   \n",
       "668                         Workbridge Associates           San Francisco   \n",
       "669                                    Salesforce           San Francisco   \n",
       "670                                 Payette Group           San Francisco   \n",
       "671                                   Pfizer Inc.           San Francisco   \n",
       "672                                      Glocomms           San Francisco   \n",
       "673                                    Clicktripz         Manhattan Beach   \n",
       "674                                          Uber           San Francisco   \n",
       "675                                       art.com              Emeryville   \n",
       "676                       The Climate Corporation           San Francisco   \n",
       "677                                   GRAIL, Inc.              Menlo Park   \n",
       "678                                        Huawei             Santa Clara   \n",
       "679                                         Honey             Los Angeles   \n",
       "680                                        Spokeo                Pasadena   \n",
       "681                                       Earnest           San Francisco   \n",
       "682                                 LogMeIn, Inc.           Santa Barbara   \n",
       "683                    Hewlett Packard Enterprise                San Jose   \n",
       "684                            GoPro Careers Page               San Mateo   \n",
       "685                                    smartdrive               San Diego   \n",
       "686                                  Grand Rounds           San Francisco   \n",
       "687                                     eBay Inc.                San Jose   \n",
       "688                         Trusted Insight, Inc.           San Francisco   \n",
       "689                                          YuMe            Redwood City   \n",
       "690                                     DataRobot           San Francisco   \n",
       "\n",
       "                                           job_summary  \\\n",
       "0    The Data Scientist role involves working on al...   \n",
       "1    The Data Scientist will be responsible for des...   \n",
       "2    Define data structures, evaluate data quality,...   \n",
       "3    Participate in data quality review activities ...   \n",
       "4    Do you like data? Experience in data analysis,...   \n",
       "5    A well-established retail company located in S...   \n",
       "6    A Series C Healthcare Startup Located in Palo ...   \n",
       "7    Analyze data to identify trends and opportunit...   \n",
       "8    2+ years of experience in data mining and/or d...   \n",
       "9    Our client, a fast-growing, well-funded, ecomm...   \n",
       "10   We are looking for a Data Scientist who will h...   \n",
       "11   We're currently looking to add another Data Sc...   \n",
       "12   Data acquisition will require navigation of Ha...   \n",
       "13   Experience with biological data. Experience wi...   \n",
       "14   Combine your love and knowledge of quantitativ...   \n",
       "15   Perform exploratory data analysis, extract dat...   \n",
       "16   We are seeking a highly-motivated Data Scienti...   \n",
       "17   Data Scientist Specialist. Core Data Scientist...   \n",
       "18   Data ScientistPalo Alto, CA6+monthsPlease look...   \n",
       "19   The Data Scientist. Data Scientist Associate P...   \n",
       "20   Provided by Dice Data Scientist, Spark, Scala,...   \n",
       "21   Analyze application data. The Data Scientist w...   \n",
       "22   And data transformations. Strong data visualiz...   \n",
       "23   Some work with Big Data technologies (Spark). ...   \n",
       "24   Extensive experience in data management and da...   \n",
       "25   Design and lead data scientists to build data ...   \n",
       "26   Functionally leading a cohesive data strategy ...   \n",
       "27   Experience with big data tech such as Spark or...   \n",
       "28   Enterprise Data and Client Insight office work...   \n",
       "29   Data Analytics, Hadoop, Cloud Computing, Data ...   \n",
       "..                                                 ...   \n",
       "661  We are seeking an experienced Data Scientist w...   \n",
       "662  Experience with data visualization tools like ...   \n",
       "663  If you have a deep passion for data and securi...   \n",
       "664  Experience in data science projects. Experienc...   \n",
       "665  Responsibilities of the Data Scientist Data Mo...   \n",
       "666  Provide subject matter expertise in statistica...   \n",
       "667  Have a passion for working on big data and pro...   \n",
       "668  Experience with geospatial data and/or data vi...   \n",
       "669  You’re intensely curious about data and highly...   \n",
       "670  Data Scientist Machine Learning. Professional ...   \n",
       "671  Associate Director- Clinical Data Scientist. T...   \n",
       "672  A leading mobile audience intelligence company...   \n",
       "673  Clicktripz is looking for a skilled Data Scien...   \n",
       "674  Large scale data management:. About the roleAs...   \n",
       "675  Art.com seeks a full-time Data Scientist to tr...   \n",
       "676  We work with weather data, agricultural statis...   \n",
       "677  Participate in data quality review activities ...   \n",
       "678  Automate data collection, pre-processing and/o...   \n",
       "679  Proficient at programming in Python and famili...   \n",
       "680  Spokeo is seeking a Senior Data Scientist to j...   \n",
       "681  Earnest is driven by data. We practice full st...   \n",
       "682  LEAD DATA SCIENTIST, MARKETING ANALYTICS. Comf...   \n",
       "683  Data Scientist to join our growing Infosight D...   \n",
       "684  Experience working with large data sets. To re...   \n",
       "685  Develop algorithms that collect continuous dat...   \n",
       "686  Data scale ranges from small data sets that fi...   \n",
       "687  We use state-of-the-art big data infrastructur...   \n",
       "688  Generate new models to classify, homogenize an...   \n",
       "689  Join YuMe as a data scientist to be part of ou...   \n",
       "690  As a Customer Facing Data Scientist, you will ...   \n",
       "\n",
       "                                             job_title  salary_estimated  \\\n",
       "0                                       data scientist           60000.0   \n",
       "1                                       data scientist           60000.0   \n",
       "2                                     data scientist 4           60000.0   \n",
       "3                 senior staff clinical data scientist           60000.0   \n",
       "4                                senior data scientist           60000.0   \n",
       "5                     senior data scientist (contract)           60000.0   \n",
       "6                             mid-level data scientist           60000.0   \n",
       "7                                       data scientist           60000.0   \n",
       "8                                       data scientist           60000.0   \n",
       "9                                       data scientist           60000.0   \n",
       "10                                      data scientist           60000.0   \n",
       "11                                      data scientist           60000.0   \n",
       "12                   research engineer/ data scientist           60000.0   \n",
       "13                                      data scientist           60000.0   \n",
       "14                      data scientist - deep learning           60000.0   \n",
       "15                                  sr. data scientist           60000.0   \n",
       "16                                 data scientist i/ii           60000.0   \n",
       "17                           data scientist specialist           60000.0   \n",
       "18                                      data scientist           60000.0   \n",
       "19                  data scientist associate principal           60000.0   \n",
       "20                      senior data scientist (remote)           60000.0   \n",
       "21                                      data scientist           60000.0   \n",
       "22                    data scientist - foster city, ca           60000.0   \n",
       "23                               junior data scientist           60000.0   \n",
       "24                                   sr data scientist           60000.0   \n",
       "25                                 lead data scientist           60000.0   \n",
       "26                                      data scientist           60000.0   \n",
       "27              junior data scientist (security space)           60000.0   \n",
       "28                        data scientist-san francisco           60000.0   \n",
       "29                                      data scientist           60000.0   \n",
       "..                                                 ...               ...   \n",
       "661                       acxiom labs - data scientist          110000.0   \n",
       "662          sr. data scientist, global insights - nlp          110000.0   \n",
       "663                      principal lead data scientist          110000.0   \n",
       "664                   signal processing data scientist          110000.0   \n",
       "665  data scientist data modeling (machine learning...          110000.0   \n",
       "666                          senior r&d data scientist          110000.0   \n",
       "667                                lead data scientist          110000.0   \n",
       "668                         data scientist (analytics)          110000.0   \n",
       "669  lead / principal data scientist - security ana...          110000.0   \n",
       "670                  data scientist - machine learning          110000.0   \n",
       "671        associate director, clinical data scientist          110000.0   \n",
       "672                                     data scientist          110000.0   \n",
       "673                                     data scientist          110000.0   \n",
       "674                            data scientist, ai labs          110000.0   \n",
       "675                                     data scientist          110000.0   \n",
       "676                       deep learning data scientist          110000.0   \n",
       "677                            clinical data scientist          110000.0   \n",
       "678                       distinguished data scientist          110000.0   \n",
       "679                              senior data scientist          110000.0   \n",
       "680                              senior data scientist          110000.0   \n",
       "681                                 sr. data scientist          110000.0   \n",
       "682           lead data scientist, marketing analytics          110000.0   \n",
       "683                                 sr. data scientist          110000.0   \n",
       "684                                 sr. data scientist          110000.0   \n",
       "685  principal data scientist, classification and f...          110000.0   \n",
       "686                              senior data scientist          110000.0   \n",
       "687                data scientist / applied researcher          110000.0   \n",
       "688                                     data scientist          110000.0   \n",
       "689                                 sr. data scientist          110000.0   \n",
       "690          partners - customer facing data scientist          110000.0   \n",
       "\n",
       "     senior_not_senior  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    1  \n",
       "4                    1  \n",
       "5                    1  \n",
       "6                    0  \n",
       "7                    0  \n",
       "8                    0  \n",
       "9                    0  \n",
       "10                   0  \n",
       "11                   0  \n",
       "12                   0  \n",
       "13                   0  \n",
       "14                   0  \n",
       "15                   1  \n",
       "16                   0  \n",
       "17                   0  \n",
       "18                   0  \n",
       "19                   1  \n",
       "20                   1  \n",
       "21                   0  \n",
       "22                   0  \n",
       "23                   0  \n",
       "24                   1  \n",
       "25                   1  \n",
       "26                   0  \n",
       "27                   0  \n",
       "28                   0  \n",
       "29                   0  \n",
       "..                 ...  \n",
       "661                  0  \n",
       "662                  1  \n",
       "663                  1  \n",
       "664                  0  \n",
       "665                  0  \n",
       "666                  1  \n",
       "667                  1  \n",
       "668                  0  \n",
       "669                  1  \n",
       "670                  0  \n",
       "671                  0  \n",
       "672                  0  \n",
       "673                  0  \n",
       "674                  0  \n",
       "675                  0  \n",
       "676                  0  \n",
       "677                  0  \n",
       "678                  0  \n",
       "679                  1  \n",
       "680                  1  \n",
       "681                  1  \n",
       "682                  1  \n",
       "683                  1  \n",
       "684                  1  \n",
       "685                  1  \n",
       "686                  1  \n",
       "687                  0  \n",
       "688                  0  \n",
       "689                  1  \n",
       "690                  0  \n",
       "\n",
       "[691 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_clean = [a[0:a.find(', CA')] for a in df_ds.job_location]\n",
    "df_ds[\"job_location\"] = loc_clean\n",
    "\n",
    "cali_index = df_ds[df_ds[\"job_location\"] == \"California\"].index\n",
    "df_ds.drop(df_ds.index[cali_index], inplace=True)\n",
    "df_ds.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing by City again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city_dummies = pd.get_dummies(df_ds.job_location)\n",
    "\n",
    "X_city = city_dummies\n",
    "y_city = df_ds[\"senior_not_senior\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_city, y_city, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.577\n",
      "Cross Validation Score:\t0.627 ± 0.041\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=300)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "acc = accuracy_score(y_test, rfc_pred)\n",
    "print \"Accuracy Score:\", acc.round(3)\n",
    "\n",
    "s = cross_val_score(rfc, X_city, y_city, cv=10, n_jobs=-1)\n",
    "print \"Cross Validation Score:\\t{:0.3} ± {:0.3}\".format(s.mean().round(3), s.std().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:800px;background:#ffff00;border:1px solid black;text-align:left;padding:8px;\">\n",
    "\n",
    "Considering a base of 50%, this is not very good, but almost expected considering a position's location should not have impact on the seniority of the position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Los Gatos</td>\n",
       "      <td>0.086900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>San Francisco Bay Area</td>\n",
       "      <td>0.074265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>0.047961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Pasadena</td>\n",
       "      <td>0.043167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Menlo Park</td>\n",
       "      <td>0.040599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Tustin</td>\n",
       "      <td>0.029254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Burbank</td>\n",
       "      <td>0.029103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Venice</td>\n",
       "      <td>0.028669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Californi</td>\n",
       "      <td>0.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Westlake Village</td>\n",
       "      <td>0.028388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Manhattan Beach</td>\n",
       "      <td>0.027720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Hollywood</td>\n",
       "      <td>0.027586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Costa Mesa</td>\n",
       "      <td>0.027562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Santa Cruz</td>\n",
       "      <td>0.027107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Redwood City</td>\n",
       "      <td>0.025158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>San Bruno</td>\n",
       "      <td>0.021811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>San Carlos</td>\n",
       "      <td>0.016813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>0.016197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Santa Monica</td>\n",
       "      <td>0.015357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beverly Hills</td>\n",
       "      <td>0.014797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  importance\n",
       "24               Los Gatos    0.086900\n",
       "45  San Francisco Bay Area    0.074265\n",
       "23             Los Angeles    0.047961\n",
       "35                Pasadena    0.043167\n",
       "27              Menlo Park    0.040599\n",
       "59                  Tustin    0.029254\n",
       "4                  Burbank    0.029103\n",
       "60                  Venice    0.028669\n",
       "6                Californi    0.028400\n",
       "61        Westlake Village    0.028388\n",
       "25         Manhattan Beach    0.027720\n",
       "18               Hollywood    0.027586\n",
       "9               Costa Mesa    0.027562\n",
       "53              Santa Cruz    0.027107\n",
       "39            Redwood City    0.025158\n",
       "41               San Bruno    0.021811\n",
       "42              San Carlos    0.016813\n",
       "34               Palo Alto    0.016197\n",
       "54            Santa Monica    0.015357\n",
       "2            Beverly Hills    0.014797"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(rfc.feature_importances_,\n",
    "                                   index = X_city.columns).reset_index()\n",
    "feature_importances.columns = ['feature', 'importance']\n",
    "\n",
    "feature_importances.sort_values('importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Vectorizer again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_w_desc = df_ds.copy(deep=False)\n",
    "\n",
    "X_summ = salaries_w_desc['job_summary']\n",
    "y_summ = salaries_w_desc['senior_not_senior']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words=\"english\")\n",
    "cv.fit(X_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_summ_trans = pd.DataFrame(cv.transform(X_summ).todense(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.asmatrix(X_summ_trans), y_summ, test_size=0.3,\n",
    "                                                    stratify=y_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data          1596\n",
       "scientist      504\n",
       "read           224\n",
       "experience     185\n",
       "science        156\n",
       "team           133\n",
       "learning       107\n",
       "looking        103\n",
       "senior         100\n",
       "analysis        95\n",
       "analytics       89\n",
       "machine         85\n",
       "large           84\n",
       "sets            78\n",
       "join            62\n",
       "big             62\n",
       "work            56\n",
       "years           52\n",
       "modeling        52\n",
       "role            51\n",
       "help            50\n",
       "working         48\n",
       "mining          48\n",
       "lead            46\n",
       "algorithms      44\n",
       "dtype: int64"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = X_summ_trans.sum(axis=0)\n",
    "word_counts.sort_values(ascending = False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.851\n",
      "Cross Validation Score: 0.882 ± 0.051\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(300)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "acc = accuracy_score(y_test, rfc_pred)\n",
    "print \"Accuracy Score:\", acc.round(3)\n",
    "\n",
    "s = cross_val_score(rfc, X_summ_trans.as_matrix(), y_summ.as_matrix(), cv=10, n_jobs=-1)\n",
    "print \"Cross Validation Score: {:0.3} ± {:0.3}\".format(s.mean().round(3), s.std().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:800px;background:#ffff00;border:1px solid black;text-align:left;padding:8px;\">\n",
    "\n",
    "This is much more promising because it shows that the job summaries seem to be accurately reflecting the seniority of a position, allowing more accurate predictions to be made. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>senior</td>\n",
       "      <td>0.099406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>principal</td>\n",
       "      <td>0.022764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>lead</td>\n",
       "      <td>0.022202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>data</td>\n",
       "      <td>0.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>scientist</td>\n",
       "      <td>0.010638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>read</td>\n",
       "      <td>0.010269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>experience</td>\n",
       "      <td>0.009751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>team</td>\n",
       "      <td>0.008452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>candidate</td>\n",
       "      <td>0.006131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>exploration</td>\n",
       "      <td>0.005955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>programming</td>\n",
       "      <td>0.005849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>learning</td>\n",
       "      <td>0.005586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>science</td>\n",
       "      <td>0.005331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>warehousing</td>\n",
       "      <td>0.005259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>defined</td>\n",
       "      <td>0.005190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>fast</td>\n",
       "      <td>0.005034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>analytics</td>\n",
       "      <td>0.004436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>algorithms</td>\n",
       "      <td>0.004387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>analysis</td>\n",
       "      <td>0.004155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>background</td>\n",
       "      <td>0.004049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature  importance\n",
       "1263       senior    0.099406\n",
       "1076    principal    0.022764\n",
       "796          lead    0.022202\n",
       "349          data    0.011400\n",
       "1238    scientist    0.010638\n",
       "1148         read    0.010269\n",
       "513    experience    0.009751\n",
       "1412         team    0.008452\n",
       "192     candidate    0.006131\n",
       "522   exploration    0.005955\n",
       "1105  programming    0.005849\n",
       "802      learning    0.005586\n",
       "1235      science    0.005331\n",
       "1536  warehousing    0.005259\n",
       "362       defined    0.005190\n",
       "544          fast    0.005034\n",
       "80      analytics    0.004436\n",
       "66     algorithms    0.004387\n",
       "75       analysis    0.004155\n",
       "139    background    0.004049"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(rfc.feature_importances_,\n",
    "                                   index = X_summ_trans.columns).reset_index()\n",
    "feature_importances.columns = ['feature', 'importance']\n",
    "\n",
    "feature_importances.sort_values('importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salary Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "salary_dummies = pd.get_dummies(df_ds.salary_estimated)\n",
    "\n",
    "X_sal = salary_dummies\n",
    "y_sal = df_ds[\"senior_not_senior\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sal, y_sal, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.582\n",
      "Cross Validation Score:\t0.632 ± 0.047\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=300)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "acc = accuracy_score(y_test, rfc_pred)\n",
    "print \"Accuracy Score:\", acc.round(3)\n",
    "\n",
    "s = cross_val_score(rfc, X_city, y_city, cv=10, n_jobs=-1)\n",
    "print \"Cross Validation Score:\\t{:0.3} ± {:0.3}\".format(s.mean().round(3), s.std().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:800px;background:#ffff00;border:1px solid black;text-align:left;padding:8px;\">\n",
    "\n",
    "Does not perform well, but again, this is expected, as different cities in California should have different expected expenses, and salaries will be adjusted according to living costs without huge emphasis on seniority of the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60000.0</td>\n",
       "      <td>0.269420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110000.0</td>\n",
       "      <td>0.249994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>0.244458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95000.0</td>\n",
       "      <td>0.236128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance\n",
       "0   60000.0    0.269420\n",
       "3  110000.0    0.249994\n",
       "1   80000.0    0.244458\n",
       "2   95000.0    0.236128"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(rfc.feature_importances_,\n",
    "                                   index = X_sal.columns).reset_index()\n",
    "feature_importances.columns = ['feature', 'importance']\n",
    "\n",
    "feature_importances.sort_values('importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine city, summary, and salary vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_w_desc = df_ds.copy(deep=False).reset_index(drop=True)\n",
    "city_dummies = pd.get_dummies(df_ds.job_location)\n",
    "\n",
    "X = pd.concat([city_dummies.reset_index(drop=True), \n",
    "               X_sal.reset_index(drop=True), \n",
    "               X_summ_trans.reset_index(drop=True)], axis=1)\n",
    "y = salaries_w_desc[\"senior_not_senior\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(691, 1636)\n",
      "(691,)\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.870192\n",
      "Cross Validation Score: 0.867 ± 0.067\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(300)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "acc = accuracy_score(y_test, rfc_pred)\n",
    "print \"Accuracy Score:\", acc.round(6)\n",
    "\n",
    "s = cross_val_score(rfc, X, y, cv=10, n_jobs=-1)\n",
    "print \"Cross Validation Score: {:0.3} ± {:0.3}\".format(s.mean().round(3), s.std().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:800px;background:#ffff00;border:1px solid black;text-align:left;padding:8px;\">\n",
    "\n",
    "Thumbs up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>senior</td>\n",
       "      <td>0.082236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>lead</td>\n",
       "      <td>0.019881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>principal</td>\n",
       "      <td>0.013036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>data</td>\n",
       "      <td>0.010560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Los Gatos</td>\n",
       "      <td>0.008950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>read</td>\n",
       "      <td>0.008460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>services</td>\n",
       "      <td>0.008439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>scientist</td>\n",
       "      <td>0.008055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>San Francisco Bay Area</td>\n",
       "      <td>0.006650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>experience</td>\n",
       "      <td>0.006357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>team</td>\n",
       "      <td>0.006287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>based</td>\n",
       "      <td>0.005599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>looking</td>\n",
       "      <td>0.005502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>analysis</td>\n",
       "      <td>0.005428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>60000</td>\n",
       "      <td>0.005351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>sense</td>\n",
       "      <td>0.005329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>streaming</td>\n",
       "      <td>0.005302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>ideas</td>\n",
       "      <td>0.005233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>diverse</td>\n",
       "      <td>0.005079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>manipulation</td>\n",
       "      <td>0.005023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feature  importance\n",
       "1332                  senior    0.082236\n",
       "865                     lead    0.019881\n",
       "1145               principal    0.013036\n",
       "418                     data    0.010560\n",
       "24                 Los Gatos    0.008950\n",
       "1217                    read    0.008460\n",
       "1344                services    0.008439\n",
       "1307               scientist    0.008055\n",
       "45    San Francisco Bay Area    0.006650\n",
       "582               experience    0.006357\n",
       "1481                    team    0.006287\n",
       "210                    based    0.005599\n",
       "899                  looking    0.005502\n",
       "144                 analysis    0.005428\n",
       "65                     60000    0.005351\n",
       "1334                   sense    0.005329\n",
       "1439               streaming    0.005302\n",
       "749                    ideas    0.005233\n",
       "489                  diverse    0.005079\n",
       "920             manipulation    0.005023"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(rfc.feature_importances_,\n",
    "                                   index = X.columns).reset_index()\n",
    "feature_importances.columns = ['feature', 'importance']\n",
    "\n",
    "feature_importances.sort_values('importance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rmodel2 = df_ds[[\"comp_name\", \"job_location\", \"salary_estimated\", \"senior_not_senior\"]]\n",
    "df_rmodel2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_rmodel2[[\"comp_name\", \"job_location\"]]\n",
    "y = df_rmodel2[\"senior_not_senior\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_params = {\n",
    "    'penalty':['l1','l2'],\n",
    "    'solver':['liblinear'],\n",
    "    'C':np.logspace(-5,0,100)\n",
    "}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr_gridsearch = GridSearchCV(lr, gs_params, cv=5, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 593 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 985 out of 1000 | elapsed:    6.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    6.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': array([  1.00000e-05,   1.12332e-05, ...,   8.90215e-01,   1.00000e+00]), 'solver': ['liblinear']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.737060041408\n"
     ]
    }
   ],
   "source": [
    "print lr_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.10974987654930568, 'penalty': 'l1', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76923076923076927"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gs = lr_gridsearch.best_estimator_\n",
    "best_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:800px;background:#ffff00;border:1px solid black;text-align:left;padding:8px;\">\n",
    "\n",
    "WIth a random forest accuracy of around 87%, the logistic regression model does not perform as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
